{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence model for english to tamil transilation using rnn encoder and decoder ( at character level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset is downloaded from http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,LSTM,Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "batch_size=64\n",
    "epochs=25\n",
    "latent_dim=256\n",
    "data_path=\"/home/santhosh/keras/rnn/rnn_encoder_decoder/data/tam.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_characters=set()\n",
    "target_characters=set()\n",
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    lines=f.read().split('\\n')\n",
    "for line in lines:\n",
    "    line=line.split('\\t')\n",
    "    if(len(line)!=2):\n",
    "        continue\n",
    "    input_text,target_text=line\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text='\\t'+target_text+'\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 180\n",
      "number of unique input token: 53\n",
      "number of unique output token: 54\n",
      "Max Sequence length for inputs: 94\n",
      "Max Sequence length for outputs: 111\n"
     ]
    }
   ],
   "source": [
    "input_characters=sorted(list(input_characters))\n",
    "targer_characters=sorted(list(target_characters))\n",
    "num_encoder_tokens=len(input_characters)\n",
    "num_decoder_tokens=len(target_characters)\n",
    "max_encoder_seq_len=max([len(text) for text in input_texts])\n",
    "max_decoder_seq_len=max([len(text) for text in target_texts])\n",
    "\n",
    "print('Number of samples:',len(input_texts))\n",
    "print('number of unique input token:',num_encoder_tokens)\n",
    "print('number of unique output token:',num_decoder_tokens)\n",
    "print('Max Sequence length for inputs:',max_encoder_seq_len)\n",
    "print('Max Sequence length for outputs:',max_decoder_seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining token2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token2index=dict([(char,i) for i,char in enumerate(input_characters)])\n",
    "target_token2index=dict([(char,i) for i,char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defing encoder_input,decoder_input and decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data=np.zeros((len(input_texts),max_encoder_seq_len,num_encoder_tokens),dtype='float32')\n",
    "decoder_input_data=np.zeros((len(input_texts),max_decoder_seq_len,num_decoder_tokens),dtype='float32')\n",
    "decoder_target_data=np.zeros((len(input_texts),max_decoder_seq_len,num_decoder_tokens),dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token2index[char]]=1\n",
    "    for t,char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token2index[char]]=1\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        if t>0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i,t-1,target_token2index[char]]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an input sequence and process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Set up the decoder, using encoder_states as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model that will turn\n",
    "## `encoder_input_data` & `decoder_input_data` into `decoder_target_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token2index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token2index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token2index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the weights\n",
      "acc: 22.12%\n",
      "\n",
      "\n",
      "file_data, iteration:4\n",
      "Iteration: 5\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 0.0770 - acc: 0.2392 - val_loss: 1.7445 - val_acc: 0.1374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_7 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_6/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_6/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0638 - acc: 0.2419 - val_loss: 1.6927 - val_acc: 0.1426\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0569 - acc: 0.2423 - val_loss: 1.6801 - val_acc: 0.1441\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0522 - acc: 0.2437 - val_loss: 1.7053 - val_acc: 0.1399\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.0519 - acc: 0.2432 - val_loss: 1.7104 - val_acc: 0.1391\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0530 - acc: 0.2432 - val_loss: 1.7075 - val_acc: 0.1411\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0513 - acc: 0.2435 - val_loss: 1.7165 - val_acc: 0.1376\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0537 - acc: 0.2419 - val_loss: 1.7168 - val_acc: 0.1426\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0523 - acc: 0.2435 - val_loss: 1.7238 - val_acc: 0.1416\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0519 - acc: 0.2428 - val_loss: 1.7112 - val_acc: 0.1431\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0523 - acc: 0.2431 - val_loss: 1.7199 - val_acc: 0.1411\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0522 - acc: 0.2428 - val_loss: 1.7143 - val_acc: 0.1424\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0510 - acc: 0.2427 - val_loss: 1.7321 - val_acc: 0.1404\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0504 - acc: 0.2438 - val_loss: 1.7207 - val_acc: 0.1401\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0493 - acc: 0.2445 - val_loss: 1.7333 - val_acc: 0.1361\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0483 - acc: 0.2445 - val_loss: 1.7372 - val_acc: 0.1416\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0502 - acc: 0.2448 - val_loss: 1.7451 - val_acc: 0.1389\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0505 - acc: 0.2448 - val_loss: 1.7566 - val_acc: 0.1349\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0546 - acc: 0.2429 - val_loss: 1.7225 - val_acc: 0.1419\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0499 - acc: 0.2445 - val_loss: 1.7412 - val_acc: 0.1386\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0487 - acc: 0.2444 - val_loss: 1.7424 - val_acc: 0.1389\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0483 - acc: 0.2449 - val_loss: 1.7560 - val_acc: 0.1341\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0474 - acc: 0.2449 - val_loss: 1.7357 - val_acc: 0.1386\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0474 - acc: 0.2444 - val_loss: 1.7551 - val_acc: 0.1369\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0482 - acc: 0.2448 - val_loss: 1.7424 - val_acc: 0.1431\n",
      "--------------------------------------------------\n",
      "I expect him to come. அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "Please sit here and wait. அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "He let go of the rope. அவன் ஓட விருப்பப் படுகிறான்\n",
      "\n",
      "You keep out of this. அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "Where do you keep your passport? அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 6\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0482 - acc: 0.2455 - val_loss: 1.7640 - val_acc: 0.1324\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0474 - acc: 0.2446 - val_loss: 1.7634 - val_acc: 0.1356\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0475 - acc: 0.2456 - val_loss: 1.7640 - val_acc: 0.1366\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0490 - acc: 0.2449 - val_loss: 1.7791 - val_acc: 0.1336\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0495 - acc: 0.2449 - val_loss: 1.7512 - val_acc: 0.1381\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0482 - acc: 0.2446 - val_loss: 1.7616 - val_acc: 0.1384\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0480 - acc: 0.2451 - val_loss: 1.7574 - val_acc: 0.1389\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0479 - acc: 0.2462 - val_loss: 1.7524 - val_acc: 0.1421\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0476 - acc: 0.2462 - val_loss: 1.7790 - val_acc: 0.1361\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0486 - acc: 0.2452 - val_loss: 1.7706 - val_acc: 0.1381\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0463 - acc: 0.2457 - val_loss: 1.7558 - val_acc: 0.1359\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0469 - acc: 0.2456 - val_loss: 1.7862 - val_acc: 0.1371\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0476 - acc: 0.2454 - val_loss: 1.8004 - val_acc: 0.1381\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0478 - acc: 0.2456 - val_loss: 1.7942 - val_acc: 0.1389\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0473 - acc: 0.2454 - val_loss: 1.7879 - val_acc: 0.1361\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0467 - acc: 0.2451 - val_loss: 1.7806 - val_acc: 0.1384\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0470 - acc: 0.2465 - val_loss: 1.7999 - val_acc: 0.1346\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0463 - acc: 0.2451 - val_loss: 1.7774 - val_acc: 0.1364\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0469 - acc: 0.2447 - val_loss: 1.7840 - val_acc: 0.1404\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0467 - acc: 0.2444 - val_loss: 1.7730 - val_acc: 0.1424\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0465 - acc: 0.2451 - val_loss: 1.7618 - val_acc: 0.1394\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0458 - acc: 0.2444 - val_loss: 1.7923 - val_acc: 0.1394\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0456 - acc: 0.2451 - val_loss: 1.7995 - val_acc: 0.1404\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0458 - acc: 0.2465 - val_loss: 1.8035 - val_acc: 0.1379\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0477 - acc: 0.2449 - val_loss: 1.7780 - val_acc: 0.1414\n",
      "--------------------------------------------------\n",
      "Calm down. அவர் உங்களுடைய நண்பரா?\n",
      "\n",
      "We swam in the lake. அவர் உங்களுடைய நண்பரா?\n",
      "\n",
      "He got a lot of money. அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "Because he's sick, he can't come. அவர் உங்களுடைய நண்பரா?\n",
      "\n",
      "He arrived after the bell rang. அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 7\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0507 - acc: 0.2434 - val_loss: 1.7698 - val_acc: 0.1416\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0455 - acc: 0.2468 - val_loss: 1.7949 - val_acc: 0.1374\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0462 - acc: 0.2454 - val_loss: 1.7889 - val_acc: 0.1379\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0460 - acc: 0.2467 - val_loss: 1.8069 - val_acc: 0.1399\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0457 - acc: 0.2458 - val_loss: 1.8109 - val_acc: 0.1369\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0454 - acc: 0.2459 - val_loss: 1.8177 - val_acc: 0.1381\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0455 - acc: 0.2451 - val_loss: 1.8007 - val_acc: 0.1364\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0458 - acc: 0.2456 - val_loss: 1.8091 - val_acc: 0.1379\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0459 - acc: 0.2456 - val_loss: 1.8260 - val_acc: 0.1359\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0458 - acc: 0.2449 - val_loss: 1.8162 - val_acc: 0.1371\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0460 - acc: 0.2461 - val_loss: 1.8177 - val_acc: 0.1354\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0472 - acc: 0.2451 - val_loss: 1.8127 - val_acc: 0.1404\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0452 - acc: 0.2463 - val_loss: 1.8276 - val_acc: 0.1384\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0453 - acc: 0.2466 - val_loss: 1.8293 - val_acc: 0.1336\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0447 - acc: 0.2452 - val_loss: 1.8114 - val_acc: 0.1424\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0458 - acc: 0.2466 - val_loss: 1.8098 - val_acc: 0.1409\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0454 - acc: 0.2471 - val_loss: 1.8344 - val_acc: 0.1384\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0466 - acc: 0.2471 - val_loss: 1.8368 - val_acc: 0.1361\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0447 - acc: 0.2472 - val_loss: 1.8252 - val_acc: 0.1366\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0453 - acc: 0.2470 - val_loss: 1.8455 - val_acc: 0.1354\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0449 - acc: 0.2461 - val_loss: 1.8151 - val_acc: 0.1414\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0450 - acc: 0.2472 - val_loss: 1.8393 - val_acc: 0.1304\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0458 - acc: 0.2465 - val_loss: 1.8316 - val_acc: 0.1379\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0452 - acc: 0.2460 - val_loss: 1.8405 - val_acc: 0.1364\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0447 - acc: 0.2468 - val_loss: 1.8412 - val_acc: 0.1346\n",
      "--------------------------------------------------\n",
      "When is your birthday? நான் டாக்ஸியிலிருந்து இறங்கினேன்\n",
      "\n",
      "Who knows? நான் டாக்ஸியிலிருந்து இறங்கினேன்\n",
      "\n",
      "Do you have a lot of pens? அவள் பாட ஆரம்பித்தாள்\n",
      "\n",
      "Do you have any gum? அவள் பாட ஆரம்பித்தாள்\n",
      "\n",
      "Keep in touch! அவன் வருவான் என எதிர் பார்க்கிறேன்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 8\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0470 - acc: 0.2461 - val_loss: 1.8233 - val_acc: 0.1369\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0449 - acc: 0.2465 - val_loss: 1.8238 - val_acc: 0.1341\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0449 - acc: 0.2464 - val_loss: 1.8297 - val_acc: 0.1361\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0449 - acc: 0.2459 - val_loss: 1.8256 - val_acc: 0.1371\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0462 - acc: 0.2462 - val_loss: 1.8217 - val_acc: 0.1376\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0448 - acc: 0.2454 - val_loss: 1.8287 - val_acc: 0.1351\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0448 - acc: 0.2462 - val_loss: 1.8253 - val_acc: 0.1379\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0442 - acc: 0.2479 - val_loss: 1.8302 - val_acc: 0.1361\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.0447 - acc: 0.2453 - val_loss: 1.8433 - val_acc: 0.1359\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0451 - acc: 0.2457 - val_loss: 1.8482 - val_acc: 0.1361\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0440 - acc: 0.2465 - val_loss: 1.8300 - val_acc: 0.1371\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0442 - acc: 0.2456 - val_loss: 1.8763 - val_acc: 0.1316\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.0452 - acc: 0.2461 - val_loss: 1.8377 - val_acc: 0.1349\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.0443 - acc: 0.2459 - val_loss: 1.8639 - val_acc: 0.1334\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0451 - acc: 0.2469 - val_loss: 1.8339 - val_acc: 0.1399\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0506 - acc: 0.2457 - val_loss: 1.8732 - val_acc: 0.1316\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0441 - acc: 0.2462 - val_loss: 1.8255 - val_acc: 0.1376\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0433 - acc: 0.2467 - val_loss: 1.8524 - val_acc: 0.1371\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0453 - acc: 0.2457 - val_loss: 1.8382 - val_acc: 0.1394\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0443 - acc: 0.2476 - val_loss: 1.8382 - val_acc: 0.1384\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0435 - acc: 0.2464 - val_loss: 1.8295 - val_acc: 0.1409\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0449 - acc: 0.2458 - val_loss: 1.8388 - val_acc: 0.1389\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0441 - acc: 0.2457 - val_loss: 1.8457 - val_acc: 0.1369\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0434 - acc: 0.2465 - val_loss: 1.8559 - val_acc: 0.1334\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0446 - acc: 0.2467 - val_loss: 1.8435 - val_acc: 0.1344\n",
      "--------------------------------------------------\n",
      "I got out of the taxi. அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "It's free of charge. அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "She went out of the room. அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "Do you know when he will come? அவள் சொல்வதைக் கேட்காதீர்\n",
      "\n",
      "I know what to do. அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 9\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0434 - acc: 0.2463 - val_loss: 1.8585 - val_acc: 0.1304\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0437 - acc: 0.2457 - val_loss: 1.8538 - val_acc: 0.1356\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0435 - acc: 0.2462 - val_loss: 1.8489 - val_acc: 0.1406\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0440 - acc: 0.2465 - val_loss: 1.8478 - val_acc: 0.1399\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0433 - acc: 0.2463 - val_loss: 1.8465 - val_acc: 0.1389\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0440 - acc: 0.2458 - val_loss: 1.8640 - val_acc: 0.1356\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0442 - acc: 0.2465 - val_loss: 1.8807 - val_acc: 0.1351\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0450 - acc: 0.2465 - val_loss: 1.8491 - val_acc: 0.1334\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0436 - acc: 0.2457 - val_loss: 1.8594 - val_acc: 0.1336\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0435 - acc: 0.2459 - val_loss: 1.8592 - val_acc: 0.1351\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0433 - acc: 0.2466 - val_loss: 1.8816 - val_acc: 0.1336\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0438 - acc: 0.2456 - val_loss: 1.8558 - val_acc: 0.1359\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0435 - acc: 0.2450 - val_loss: 1.8606 - val_acc: 0.1351\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0428 - acc: 0.2462 - val_loss: 1.8457 - val_acc: 0.1371\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0433 - acc: 0.2467 - val_loss: 1.8779 - val_acc: 0.1266\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.1855 - acc: 0.2066 - val_loss: 1.7139 - val_acc: 0.1326\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.1196 - acc: 0.2251 - val_loss: 1.7382 - val_acc: 0.1364\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0744 - acc: 0.2386 - val_loss: 1.7091 - val_acc: 0.1381\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0632 - acc: 0.2415 - val_loss: 1.7189 - val_acc: 0.1399\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0590 - acc: 0.2426 - val_loss: 1.7275 - val_acc: 0.1399\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0568 - acc: 0.2422 - val_loss: 1.7376 - val_acc: 0.1351\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0554 - acc: 0.2425 - val_loss: 1.7449 - val_acc: 0.1361\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0515 - acc: 0.2442 - val_loss: 1.7561 - val_acc: 0.1341\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0497 - acc: 0.2448 - val_loss: 1.7760 - val_acc: 0.1324\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0491 - acc: 0.2451 - val_loss: 1.7820 - val_acc: 0.1309\n",
      "--------------------------------------------------\n",
      "I am afraid of bears. அவள் அவனுக்கு நிச்சயிக்கப் பட்டாள்\n",
      "\n",
      "She has never been in a car driven by him. அவள் அவனுக்கு நிச்சயிக்கப் பட்டாள்\n",
      "\n",
      "She bit him. அவள் அவனுக்கு நிச்சயிக்கப் பட்டாள்\n",
      "\n",
      "Come and see me. அவள் அவனுக்கு நிச்சயிக்கப் பட்டாள்\n",
      "\n",
      "She began to sing. அவள் அவனுக்கு நிச்சயிக்கப் பட்டாள்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 10\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0488 - acc: 0.2444 - val_loss: 1.7731 - val_acc: 0.1376\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0475 - acc: 0.2457 - val_loss: 1.7858 - val_acc: 0.1309\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0486 - acc: 0.2451 - val_loss: 1.8017 - val_acc: 0.1356\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0488 - acc: 0.2448 - val_loss: 1.7929 - val_acc: 0.1369\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0478 - acc: 0.2442 - val_loss: 1.7924 - val_acc: 0.1344\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0470 - acc: 0.2451 - val_loss: 1.7820 - val_acc: 0.1414\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0483 - acc: 0.2459 - val_loss: 1.7955 - val_acc: 0.1339\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0509 - acc: 0.2439 - val_loss: 1.8046 - val_acc: 0.1334\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0487 - acc: 0.2455 - val_loss: 1.8154 - val_acc: 0.1306\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0483 - acc: 0.2449 - val_loss: 1.8327 - val_acc: 0.1301\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0480 - acc: 0.2446 - val_loss: 1.8189 - val_acc: 0.1364\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0470 - acc: 0.2452 - val_loss: 1.8060 - val_acc: 0.1356\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0471 - acc: 0.2446 - val_loss: 1.8189 - val_acc: 0.1329\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0473 - acc: 0.2441 - val_loss: 1.8285 - val_acc: 0.1321\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0479 - acc: 0.2442 - val_loss: 1.8262 - val_acc: 0.1296\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0489 - acc: 0.2439 - val_loss: 1.8146 - val_acc: 0.1291\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0468 - acc: 0.2439 - val_loss: 1.8305 - val_acc: 0.1306\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0467 - acc: 0.2448 - val_loss: 1.8288 - val_acc: 0.1339\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0479 - acc: 0.2437 - val_loss: 1.8274 - val_acc: 0.1396\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0471 - acc: 0.2457 - val_loss: 1.8427 - val_acc: 0.1344\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0463 - acc: 0.2446 - val_loss: 1.8271 - val_acc: 0.1359\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.0624 - acc: 0.2408 - val_loss: 1.7829 - val_acc: 0.1334\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0539 - acc: 0.2423 - val_loss: 1.7167 - val_acc: 0.1376\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.0669 - acc: 0.2409 - val_loss: 1.7553 - val_acc: 0.1309\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0529 - acc: 0.2434 - val_loss: 1.7478 - val_acc: 0.1344\n",
      "--------------------------------------------------\n",
      "That's our house. அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "I have to dress up. அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "She wore a beautiful dress. அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "I am afraid of bears. அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "We ran out of food. அவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 11\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0461 - acc: 0.2458 - val_loss: 1.7636 - val_acc: 0.1384\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0453 - acc: 0.2455 - val_loss: 1.7666 - val_acc: 0.1379\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0451 - acc: 0.2455 - val_loss: 1.7699 - val_acc: 0.1346\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0452 - acc: 0.2450 - val_loss: 1.7867 - val_acc: 0.1376\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0452 - acc: 0.2464 - val_loss: 1.7863 - val_acc: 0.1369\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0445 - acc: 0.2455 - val_loss: 1.7991 - val_acc: 0.1361\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0445 - acc: 0.2456 - val_loss: 1.7938 - val_acc: 0.1361\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0454 - acc: 0.2454 - val_loss: 1.7905 - val_acc: 0.1371\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0455 - acc: 0.2457 - val_loss: 1.8058 - val_acc: 0.1361\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0456 - acc: 0.2459 - val_loss: 1.8116 - val_acc: 0.1369\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0465 - acc: 0.2449 - val_loss: 1.8005 - val_acc: 0.1326\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0459 - acc: 0.2452 - val_loss: 1.8026 - val_acc: 0.1374\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0453 - acc: 0.2461 - val_loss: 1.8087 - val_acc: 0.1376\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0506 - acc: 0.2452 - val_loss: 1.8144 - val_acc: 0.1344\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0464 - acc: 0.2462 - val_loss: 1.8301 - val_acc: 0.1349\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0454 - acc: 0.2453 - val_loss: 1.8258 - val_acc: 0.1364\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0456 - acc: 0.2445 - val_loss: 1.8284 - val_acc: 0.1349\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0457 - acc: 0.2452 - val_loss: 1.8395 - val_acc: 0.1329\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0452 - acc: 0.2451 - val_loss: 1.8297 - val_acc: 0.1336\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0452 - acc: 0.2456 - val_loss: 1.8333 - val_acc: 0.1349\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0455 - acc: 0.2446 - val_loss: 1.8444 - val_acc: 0.1319\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0452 - acc: 0.2442 - val_loss: 1.8478 - val_acc: 0.1339\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0451 - acc: 0.2448 - val_loss: 1.8281 - val_acc: 0.1366\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0452 - acc: 0.2454 - val_loss: 1.8275 - val_acc: 0.1361\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0451 - acc: 0.2449 - val_loss: 1.8413 - val_acc: 0.1321\n",
      "--------------------------------------------------\n",
      "I am tired of my work. நான் டாக்ஸியிலிருந்து இறங்கினேன்\n",
      "\n",
      "She has never been in a car driven by him. நான் டாக்ஸியிலிருந்து இறங்கினேன்\n",
      "\n",
      "Is he a friend of yours? நான் டாக்ஸியிலிருந்து இறங்கினேன்\n",
      "\n",
      "He's afraid of the sea. நான் டாக்ஸியிலிருந்து இறங்கினேன்\n",
      "\n",
      "It's the third biggest city of Serbia. நான் டாக்ஸியிலிருந்து இறங்கினேன்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 12\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0458 - acc: 0.2442 - val_loss: 1.8334 - val_acc: 0.1336\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.0457 - acc: 0.2452 - val_loss: 1.8344 - val_acc: 0.1349\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0446 - acc: 0.2461 - val_loss: 1.8530 - val_acc: 0.1334\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0460 - acc: 0.2447 - val_loss: 1.8402 - val_acc: 0.1324\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0444 - acc: 0.2452 - val_loss: 1.8579 - val_acc: 0.1334\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0440 - acc: 0.2450 - val_loss: 1.8503 - val_acc: 0.1314\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0451 - acc: 0.2452 - val_loss: 1.8343 - val_acc: 0.1379\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0448 - acc: 0.2465 - val_loss: 1.8580 - val_acc: 0.1344\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0443 - acc: 0.2454 - val_loss: 1.8689 - val_acc: 0.1331\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0446 - acc: 0.2459 - val_loss: 1.8786 - val_acc: 0.1354\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0493 - acc: 0.2449 - val_loss: 1.8476 - val_acc: 0.1314\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0449 - acc: 0.2442 - val_loss: 1.8517 - val_acc: 0.1304\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0442 - acc: 0.2454 - val_loss: 1.8599 - val_acc: 0.1339\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0449 - acc: 0.2453 - val_loss: 1.8667 - val_acc: 0.1311\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0443 - acc: 0.2442 - val_loss: 1.8506 - val_acc: 0.1359\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0449 - acc: 0.2446 - val_loss: 1.8668 - val_acc: 0.1296\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0451 - acc: 0.2446 - val_loss: 1.8742 - val_acc: 0.1294\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0437 - acc: 0.2449 - val_loss: 1.8649 - val_acc: 0.1341\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0438 - acc: 0.2444 - val_loss: 1.8587 - val_acc: 0.1301\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0436 - acc: 0.2468 - val_loss: 1.8515 - val_acc: 0.1349\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0448 - acc: 0.2439 - val_loss: 1.8740 - val_acc: 0.1336\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0447 - acc: 0.2437 - val_loss: 1.8628 - val_acc: 0.1294\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0475 - acc: 0.2442 - val_loss: 1.8819 - val_acc: 0.1269\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0439 - acc: 0.2440 - val_loss: 1.8695 - val_acc: 0.1321\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0443 - acc: 0.2439 - val_loss: 1.8932 - val_acc: 0.1281\n",
      "--------------------------------------------------\n",
      "We ran out of food. அவர் உங்களுடைய நண்பரா?\n",
      "\n",
      "He is still here. அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "She has 2,000 books. அவர் உங்களுடைய நண்பரா?\n",
      "\n",
      "Don't lie to me. அவர் உங்களுடைய நண்பரா?\n",
      "\n",
      "Tom runs very fast. அவர் உங்களுடைய நண்பரா?\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 13\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0441 - acc: 0.2446 - val_loss: 1.8911 - val_acc: 0.1306\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0452 - acc: 0.2443 - val_loss: 1.8610 - val_acc: 0.1301\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0443 - acc: 0.2455 - val_loss: 1.8695 - val_acc: 0.1274\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0438 - acc: 0.2457 - val_loss: 1.8619 - val_acc: 0.1321\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0440 - acc: 0.2449 - val_loss: 1.8833 - val_acc: 0.1284\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0495 - acc: 0.2429 - val_loss: 1.7684 - val_acc: 0.1401\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0531 - acc: 0.2462 - val_loss: 1.8079 - val_acc: 0.1429\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0448 - acc: 0.2456 - val_loss: 1.8295 - val_acc: 0.1411\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0441 - acc: 0.2461 - val_loss: 1.8242 - val_acc: 0.1444\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0449 - acc: 0.2453 - val_loss: 1.8137 - val_acc: 0.1411\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.0478 - acc: 0.2450 - val_loss: 1.8025 - val_acc: 0.1404\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0456 - acc: 0.2459 - val_loss: 1.8088 - val_acc: 0.1424\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0441 - acc: 0.2456 - val_loss: 1.8164 - val_acc: 0.1389\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0441 - acc: 0.2464 - val_loss: 1.8239 - val_acc: 0.1406\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0440 - acc: 0.2459 - val_loss: 1.8251 - val_acc: 0.1436\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0446 - acc: 0.2462 - val_loss: 1.8375 - val_acc: 0.1409\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0437 - acc: 0.2459 - val_loss: 1.8501 - val_acc: 0.1391\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0433 - acc: 0.2461 - val_loss: 1.8577 - val_acc: 0.1361\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0430 - acc: 0.2459 - val_loss: 1.8523 - val_acc: 0.1381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0437 - acc: 0.2458 - val_loss: 1.8585 - val_acc: 0.1391\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0440 - acc: 0.2459 - val_loss: 1.8563 - val_acc: 0.1389\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.0440 - acc: 0.2450 - val_loss: 1.8664 - val_acc: 0.1326\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.0449 - acc: 0.2449 - val_loss: 1.8732 - val_acc: 0.1349\n",
      "Epoch 24/25\n",
      " 64/144 [============>.................] - ETA: 1s - loss: 0.0414 - acc: 0.2514"
     ]
    }
   ],
   "source": [
    "\n",
    "iteration=0\n",
    "\n",
    "# load weights\n",
    "print('loading the weights')\n",
    "model.load_weights(\"weights_best.hdf5\")\n",
    "\n",
    "# estimate accuracy on whole dataset using loaded weights\n",
    "scores = model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data,verbose=0)\n",
    "print(\"%s: %.2f%%\\n\\n\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "iteration_file=\"/home/santhosh/keras/rnn/rnn_encoder_decoder/iteration.txt\"\n",
    "try:\n",
    "    file=open(iteration_file,'r')\n",
    "    last_line=file.read().split('\\n')[-2]\n",
    "    print('file_data,',last_line)\n",
    "    iteration=int(last_line.split(':')[1])\n",
    "    #print(iteration)\n",
    "    file.close()\n",
    "    \n",
    "except:\n",
    "    print('no file exist')\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "while True:\n",
    "    print('Iteration:',iteration+1)\n",
    "    #training\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,callbacks=callbacks_list)\n",
    "    #prepare sample_data to test 5 samples:\n",
    "    print(\"-\"*50)\n",
    "    for i in range(5):\n",
    "        index=np.random.randint(len(input_texts))\n",
    "        encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "        output_sequence=decode_sequence(encoded_input_sequence)\n",
    "        print(input_texts[index],output_sequence)\n",
    "    print(\"-\"*50)\n",
    "    # Save model\n",
    "    file=open(iteration_file,'a')\n",
    "    file.write('iteration:'+str(iteration+1)+'\\n')\n",
    "    file.close()\n",
    "    iteration+=1\n",
    "    model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
