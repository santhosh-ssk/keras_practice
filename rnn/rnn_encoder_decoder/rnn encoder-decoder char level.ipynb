{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence model for english to tamil transilation using rnn encoder and decoder ( at character level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset is downloaded from http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Input,LSTM,Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "batch_size=64\n",
    "epochs=25\n",
    "latent_dim=256\n",
    "data_path=\"/home/santhosh/keras/rnn/rnn_encoder_decoder/data/tam.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_characters=set()\n",
    "target_characters=set()\n",
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    lines=f.read().split('\\n')\n",
    "for line in lines:\n",
    "    line=line.split('\\t')\n",
    "    if(len(line)!=2):\n",
    "        continue\n",
    "    input_text,target_text=line\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text='\\t'+target_text+'\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 180\n",
      "number of unique input token: 53\n",
      "number of unique output token: 54\n",
      "Max Sequence length for inputs: 94\n",
      "Max Sequence length for outputs: 111\n"
     ]
    }
   ],
   "source": [
    "input_characters=sorted(list(input_characters))\n",
    "targer_characters=sorted(list(target_characters))\n",
    "num_encoder_tokens=len(input_characters)\n",
    "num_decoder_tokens=len(target_characters)\n",
    "max_encoder_seq_len=max([len(text) for text in input_texts])\n",
    "max_decoder_seq_len=max([len(text) for text in target_texts])\n",
    "\n",
    "print('Number of samples:',len(input_texts))\n",
    "print('number of unique input token:',num_encoder_tokens)\n",
    "print('number of unique output token:',num_decoder_tokens)\n",
    "print('Max Sequence length for inputs:',max_encoder_seq_len)\n",
    "print('Max Sequence length for outputs:',max_decoder_seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining token2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token2index=dict([(char,i) for i,char in enumerate(input_characters)])\n",
    "target_token2index=dict([(char,i) for i,char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defing encoder_input,decoder_input and decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data=np.zeros((len(input_texts),max_encoder_seq_len,num_encoder_tokens),dtype='float32')\n",
    "decoder_input_data=np.zeros((len(input_texts),max_decoder_seq_len,num_decoder_tokens),dtype='float32')\n",
    "decoder_target_data=np.zeros((len(input_texts),max_decoder_seq_len,num_decoder_tokens),dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token2index[char]]=1\n",
    "    for t,char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token2index[char]]=1\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        if t>0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i,t-1,target_token2index[char]]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an input sequence and process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Set up the decoder, using encoder_states as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model that will turn\n",
    "## `encoder_input_data` & `decoder_input_data` into `decoder_target_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token2index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token2index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token2index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no file exist\n",
      "Iteration: 1\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.7078 - acc: 0.8024 - val_loss: 1.2087 - val_acc: 0.6829\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 47ms/step - loss: 0.7040 - acc: 0.4950 - val_loss: 1.2146 - val_acc: 0.6762\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.6941 - acc: 0.8037 - val_loss: 1.1943 - val_acc: 0.6897\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.6882 - acc: 0.8108 - val_loss: 1.1677 - val_acc: 0.6794\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.6900 - acc: 0.7140 - val_loss: 1.1791 - val_acc: 0.6794\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.6767 - acc: 0.4929 - val_loss: 1.1689 - val_acc: 0.6847\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.6741 - acc: 0.8072 - val_loss: 1.1682 - val_acc: 0.6899\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.6658 - acc: 0.7367 - val_loss: 1.1683 - val_acc: 0.6839\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.6573 - acc: 0.5067 - val_loss: 1.1774 - val_acc: 0.1094\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.6505 - acc: 0.5013 - val_loss: 1.1905 - val_acc: 0.6872\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.6577 - acc: 0.8031 - val_loss: 1.1501 - val_acc: 0.1051\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.6430 - acc: 0.4931 - val_loss: 1.1344 - val_acc: 0.1374\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.6349 - acc: 0.5156 - val_loss: 1.1327 - val_acc: 0.6814\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.6291 - acc: 0.8148 - val_loss: 1.0993 - val_acc: 0.1627\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.6187 - acc: 0.5313 - val_loss: 1.1098 - val_acc: 0.6889\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.6144 - acc: 0.8158 - val_loss: 1.0875 - val_acc: 0.6942\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.6247 - acc: 0.7711 - val_loss: 1.1113 - val_acc: 0.6794\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.6135 - acc: 0.4986 - val_loss: 1.0965 - val_acc: 0.6752\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.5988 - acc: 0.8176 - val_loss: 1.0717 - val_acc: 0.7022\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.5930 - acc: 0.7446 - val_loss: 1.0998 - val_acc: 0.6972\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.5905 - acc: 0.5337 - val_loss: 1.0740 - val_acc: 0.7005\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.5894 - acc: 0.5094 - val_loss: 1.0769 - val_acc: 0.1319\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.5812 - acc: 0.4364 - val_loss: 1.0951 - val_acc: 0.1201\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.5852 - acc: 0.5125 - val_loss: 1.0456 - val_acc: 0.7032\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.5707 - acc: 0.8255 - val_loss: 1.0911 - val_acc: 0.6321\n",
      "--------------------------------------------------\n",
      "I am engaged to her. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Come and help us. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "He is fond of swimming. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "He is afraid of death. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "She glanced through the magazine. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 2\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.5773 - acc: 0.8037 - val_loss: 1.0498 - val_acc: 0.7080\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.5586 - acc: 0.8292 - val_loss: 1.0424 - val_acc: 0.1404\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.5962 - acc: 0.5035 - val_loss: 1.0447 - val_acc: 0.1346\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.5754 - acc: 0.4933 - val_loss: 1.0180 - val_acc: 0.7155\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.5652 - acc: 0.8209 - val_loss: 1.0355 - val_acc: 0.1296\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.5641 - acc: 0.4286 - val_loss: 1.0388 - val_acc: 0.2535\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.5563 - acc: 0.5541 - val_loss: 1.0178 - val_acc: 0.1391\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.5468 - acc: 0.5173 - val_loss: 1.0194 - val_acc: 0.6694\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.5357 - acc: 0.8181 - val_loss: 1.0593 - val_acc: 0.6299\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.5392 - acc: 0.7810 - val_loss: 0.9989 - val_acc: 0.6844\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.5267 - acc: 0.8186 - val_loss: 1.0099 - val_acc: 0.1476\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.5255 - acc: 0.5176 - val_loss: 1.0029 - val_acc: 0.1459\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.5210 - acc: 0.4763 - val_loss: 0.9763 - val_acc: 0.6491\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.5135 - acc: 0.7381 - val_loss: 1.0022 - val_acc: 0.6887\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.5127 - acc: 0.5386 - val_loss: 1.0069 - val_acc: 0.2310\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.5076 - acc: 0.5091 - val_loss: 1.0068 - val_acc: 0.7145\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.5101 - acc: 0.5037 - val_loss: 0.9775 - val_acc: 0.1502\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.4955 - acc: 0.4430 - val_loss: 0.9721 - val_acc: 0.7085\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4980 - acc: 0.4997 - val_loss: 0.9627 - val_acc: 0.2355\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4870 - acc: 0.2506 - val_loss: 0.9763 - val_acc: 0.6764\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4905 - acc: 0.7721 - val_loss: 0.9916 - val_acc: 0.1619\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.4854 - acc: 0.5166 - val_loss: 0.9965 - val_acc: 0.1389\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.4865 - acc: 0.4476 - val_loss: 0.9850 - val_acc: 0.1449\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.4806 - acc: 0.5077 - val_loss: 0.9772 - val_acc: 0.1727\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4671 - acc: 0.1848 - val_loss: 0.9538 - val_acc: 0.1647\n",
      "--------------------------------------------------\n",
      "I have to dress up. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Which of them is your brother? ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Keep in touch! ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I expect him to come. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "She has never been in a car driven by him. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 3\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4643 - acc: 0.4535 - val_loss: 0.9640 - val_acc: 0.5991\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4702 - acc: 0.6846 - val_loss: 0.9920 - val_acc: 0.2080\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4767 - acc: 0.2418 - val_loss: 0.9525 - val_acc: 0.2082\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4618 - acc: 0.3507 - val_loss: 0.9576 - val_acc: 0.4162\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.4592 - acc: 0.3141 - val_loss: 0.9643 - val_acc: 0.1406\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.4542 - acc: 0.1530 - val_loss: 0.9634 - val_acc: 0.1436\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.4511 - acc: 0.4313 - val_loss: 0.9357 - val_acc: 0.1727\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.4566 - acc: 0.4587 - val_loss: 0.9360 - val_acc: 0.5115\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4467 - acc: 0.4260 - val_loss: 0.9460 - val_acc: 0.2990\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.4405 - acc: 0.4833 - val_loss: 0.9586 - val_acc: 0.1446\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.4573 - acc: 0.4112 - val_loss: 0.9430 - val_acc: 0.1509\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4467 - acc: 0.1413 - val_loss: 0.9428 - val_acc: 0.2422\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4344 - acc: 0.2035 - val_loss: 0.9220 - val_acc: 0.3624\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4317 - acc: 0.3212 - val_loss: 0.9674 - val_acc: 0.1451\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4272 - acc: 0.2130 - val_loss: 0.9397 - val_acc: 0.1737\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4262 - acc: 0.2126 - val_loss: 0.9284 - val_acc: 0.3554\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.4220 - acc: 0.3424 - val_loss: 0.9332 - val_acc: 0.4402\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4174 - acc: 0.3975 - val_loss: 0.9450 - val_acc: 0.1429\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4151 - acc: 0.1489 - val_loss: 0.9153 - val_acc: 0.1552\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.4153 - acc: 0.2167 - val_loss: 0.9264 - val_acc: 0.1574\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.4038 - acc: 0.1797 - val_loss: 0.9422 - val_acc: 0.1709\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.4047 - acc: 0.1650 - val_loss: 0.9503 - val_acc: 0.2975\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.4016 - acc: 0.2526 - val_loss: 0.9556 - val_acc: 0.1522\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3999 - acc: 0.3725 - val_loss: 0.9345 - val_acc: 0.1512\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3945 - acc: 0.1644 - val_loss: 0.9552 - val_acc: 0.1499\n",
      "--------------------------------------------------\n",
      "When does it begin? ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "A square has four sides. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "You keep out of this. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "He went in place of me. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I have to dress up. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 4\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.3930 - acc: 0.1639 - val_loss: 0.9200 - val_acc: 0.1584\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.3867 - acc: 0.2041 - val_loss: 0.9486 - val_acc: 0.1834\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.3927 - acc: 0.2427 - val_loss: 0.9479 - val_acc: 0.1944\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3828 - acc: 0.1893 - val_loss: 0.9453 - val_acc: 0.1587\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3804 - acc: 0.1661 - val_loss: 0.9351 - val_acc: 0.1779\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3746 - acc: 0.1790 - val_loss: 0.9367 - val_acc: 0.1814\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.3696 - acc: 0.2245 - val_loss: 0.9518 - val_acc: 0.1829\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.3701 - acc: 0.1883 - val_loss: 0.9470 - val_acc: 0.1644\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.3730 - acc: 0.1715 - val_loss: 0.9521 - val_acc: 0.1564\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3669 - acc: 0.2039 - val_loss: 0.9278 - val_acc: 0.3741\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3659 - acc: 0.2947 - val_loss: 0.9572 - val_acc: 0.2012\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.3654 - acc: 0.2040 - val_loss: 0.9270 - val_acc: 0.1934\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.3610 - acc: 0.1969 - val_loss: 0.9293 - val_acc: 0.2265\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.3535 - acc: 0.2133 - val_loss: 0.9678 - val_acc: 0.1662\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.3537 - acc: 0.2093 - val_loss: 0.9484 - val_acc: 0.1969\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.3539 - acc: 0.2302 - val_loss: 0.9234 - val_acc: 0.1604\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3545 - acc: 0.2415 - val_loss: 0.9342 - val_acc: 0.2110\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3477 - acc: 0.2250 - val_loss: 0.9722 - val_acc: 0.1542\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3603 - acc: 0.2058 - val_loss: 0.9364 - val_acc: 0.1824\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3433 - acc: 0.2171 - val_loss: 0.9524 - val_acc: 0.2437\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.3373 - acc: 0.2614 - val_loss: 0.9214 - val_acc: 0.3063\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3464 - acc: 0.3261 - val_loss: 0.9408 - val_acc: 0.1602\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3321 - acc: 0.2589 - val_loss: 0.9438 - val_acc: 0.2195\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3241 - acc: 0.2598 - val_loss: 0.9556 - val_acc: 0.1607\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3257 - acc: 0.2289 - val_loss: 0.9538 - val_acc: 0.2808\n",
      "--------------------------------------------------\n",
      "He let go of the rope. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I don't think people use that word anymore. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "She is not afraid of anything. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Give it to her. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "This apple is sweet. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 5\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3339 - acc: 0.2554 - val_loss: 0.9515 - val_acc: 0.2718\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3214 - acc: 0.3133 - val_loss: 0.9618 - val_acc: 0.2457\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.3221 - acc: 0.2589 - val_loss: 0.9685 - val_acc: 0.2142\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3245 - acc: 0.2279 - val_loss: 0.9742 - val_acc: 0.2307\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3210 - acc: 0.2401 - val_loss: 0.9454 - val_acc: 0.2220\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3123 - acc: 0.2489 - val_loss: 0.9640 - val_acc: 0.1652\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.3107 - acc: 0.2282 - val_loss: 0.9656 - val_acc: 0.1922\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.3003 - acc: 0.2342 - val_loss: 0.9489 - val_acc: 0.2968\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.2995 - acc: 0.3074 - val_loss: 0.9732 - val_acc: 0.1989\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.2984 - acc: 0.2833 - val_loss: 0.9480 - val_acc: 0.2312\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.2915 - acc: 0.2667 - val_loss: 0.9761 - val_acc: 0.1707\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2903 - acc: 0.2434 - val_loss: 1.0083 - val_acc: 0.2227\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2965 - acc: 0.2575 - val_loss: 0.9773 - val_acc: 0.1647\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2926 - acc: 0.2396 - val_loss: 0.9717 - val_acc: 0.1932\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2918 - acc: 0.2377 - val_loss: 0.9834 - val_acc: 0.2215\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.2773 - acc: 0.2501 - val_loss: 0.9681 - val_acc: 0.1954\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2779 - acc: 0.2526 - val_loss: 0.9727 - val_acc: 0.1694\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.2718 - acc: 0.2313 - val_loss: 0.9886 - val_acc: 0.2040\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.2789 - acc: 0.2807 - val_loss: 0.9739 - val_acc: 0.2505\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.2704 - acc: 0.3017 - val_loss: 1.0095 - val_acc: 0.1839\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2720 - acc: 0.3141 - val_loss: 1.0006 - val_acc: 0.3131\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.2711 - acc: 0.2850 - val_loss: 0.9747 - val_acc: 0.2360\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.2578 - acc: 0.2995 - val_loss: 0.9973 - val_acc: 0.2487\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.2807 - acc: 0.2753 - val_loss: 0.9895 - val_acc: 0.1654\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.2557 - acc: 0.2614 - val_loss: 1.0008 - val_acc: 0.2452\n",
      "--------------------------------------------------\n",
      "Come and see me. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I know every inch of the town. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "She sat next to me. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I don't think people use that word anymore. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I am tired of my work. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 6\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.2526 - acc: 0.3038 - val_loss: 1.0224 - val_acc: 0.3086\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.2585 - acc: 0.3164 - val_loss: 0.9793 - val_acc: 0.2200\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.2507 - acc: 0.3097 - val_loss: 1.0058 - val_acc: 0.1814\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.2443 - acc: 0.2717 - val_loss: 1.0181 - val_acc: 0.1999\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.2448 - acc: 0.2892 - val_loss: 1.0291 - val_acc: 0.2095\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.2336 - acc: 0.2737 - val_loss: 1.0199 - val_acc: 0.2285\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.2337 - acc: 0.2787 - val_loss: 1.0298 - val_acc: 0.1667\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2336 - acc: 0.2648 - val_loss: 1.0227 - val_acc: 0.2067\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.2301 - acc: 0.2690 - val_loss: 1.0260 - val_acc: 0.2252\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.2320 - acc: 0.2929 - val_loss: 1.0240 - val_acc: 0.2295\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2187 - acc: 0.2827 - val_loss: 1.0663 - val_acc: 0.1919\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2235 - acc: 0.2794 - val_loss: 1.0486 - val_acc: 0.2150\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.2224 - acc: 0.2703 - val_loss: 1.0329 - val_acc: 0.2432\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.2254 - acc: 0.2715 - val_loss: 1.0582 - val_acc: 0.1887\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.2122 - acc: 0.2683 - val_loss: 1.0466 - val_acc: 0.1922\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.2107 - acc: 0.2651 - val_loss: 1.0488 - val_acc: 0.1837\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.2119 - acc: 0.2815 - val_loss: 1.0463 - val_acc: 0.1939\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.2076 - acc: 0.2729 - val_loss: 1.0590 - val_acc: 0.1959\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.2063 - acc: 0.2706 - val_loss: 1.0513 - val_acc: 0.2012\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1919 - acc: 0.2835 - val_loss: 1.0646 - val_acc: 0.1834\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.1907 - acc: 0.2903 - val_loss: 1.0643 - val_acc: 0.1759\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.1968 - acc: 0.2869 - val_loss: 1.0973 - val_acc: 0.2230\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1923 - acc: 0.3077 - val_loss: 1.0721 - val_acc: 0.2247\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1925 - acc: 0.2955 - val_loss: 1.0716 - val_acc: 0.2397\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.1925 - acc: 0.3066 - val_loss: 1.0899 - val_acc: 0.2340\n",
      "--------------------------------------------------\n",
      "We started to walk. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I had to walk home. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Speak slowly and clearly. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Which of them is your brother? ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "May I speak to you? ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 7\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1934 - acc: 0.2916 - val_loss: 1.0653 - val_acc: 0.1877\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.1758 - acc: 0.2911 - val_loss: 1.0898 - val_acc: 0.2270\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.1791 - acc: 0.3116 - val_loss: 1.1017 - val_acc: 0.2032\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.1729 - acc: 0.3017 - val_loss: 1.0889 - val_acc: 0.2047\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.1731 - acc: 0.2855 - val_loss: 1.0961 - val_acc: 0.1782\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.1759 - acc: 0.2726 - val_loss: 1.1176 - val_acc: 0.2945\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.1753 - acc: 0.3155 - val_loss: 1.1026 - val_acc: 0.1774\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.1719 - acc: 0.2848 - val_loss: 1.1092 - val_acc: 0.2480\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 0.1680 - acc: 0.3003 - val_loss: 1.1232 - val_acc: 0.1999\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 0.1632 - acc: 0.2915 - val_loss: 1.1043 - val_acc: 0.2195\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.1586 - acc: 0.3044 - val_loss: 1.1277 - val_acc: 0.1919\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.1644 - acc: 0.2979 - val_loss: 1.1068 - val_acc: 0.2775\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.1609 - acc: 0.3361 - val_loss: 1.1377 - val_acc: 0.1517\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.1633 - acc: 0.2882 - val_loss: 1.1151 - val_acc: 0.2027\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.1485 - acc: 0.2924 - val_loss: 1.1257 - val_acc: 0.1904\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.1421 - acc: 0.2967 - val_loss: 1.1465 - val_acc: 0.1917\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 0.1537 - acc: 0.3026 - val_loss: 1.1591 - val_acc: 0.1857\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 0.1437 - acc: 0.3094 - val_loss: 1.1421 - val_acc: 0.2040\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.1502 - acc: 0.3001 - val_loss: 1.1481 - val_acc: 0.2330\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.1511 - acc: 0.3056 - val_loss: 1.1623 - val_acc: 0.2482\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.1514 - acc: 0.3124 - val_loss: 1.1624 - val_acc: 0.2150\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.1424 - acc: 0.2949 - val_loss: 1.1682 - val_acc: 0.1867\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.1342 - acc: 0.3034 - val_loss: 1.1667 - val_acc: 0.1927\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.1323 - acc: 0.3001 - val_loss: 1.1767 - val_acc: 0.2480\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.1413 - acc: 0.3249 - val_loss: 1.1835 - val_acc: 0.1864\n",
      "--------------------------------------------------\n",
      "Go and sit by your father. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Come and see me. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I have to leave now. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Keep to the right. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "We ran after the thief. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 8\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.1294 - acc: 0.2985 - val_loss: 1.1751 - val_acc: 0.1852\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 8s 59ms/step - loss: 0.1432 - acc: 0.3122 - val_loss: 1.1971 - val_acc: 0.2437\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.1350 - acc: 0.3157 - val_loss: 1.1975 - val_acc: 0.1984\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.1241 - acc: 0.3075 - val_loss: 1.1875 - val_acc: 0.1982\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.1222 - acc: 0.3129 - val_loss: 1.1963 - val_acc: 0.2075\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.1213 - acc: 0.3045 - val_loss: 1.1870 - val_acc: 0.1859\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.1279 - acc: 0.2982 - val_loss: 1.2159 - val_acc: 0.1839\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1293 - acc: 0.2965 - val_loss: 1.2123 - val_acc: 0.1772\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1202 - acc: 0.2977 - val_loss: 1.2003 - val_acc: 0.1974\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.1240 - acc: 0.3177 - val_loss: 1.2028 - val_acc: 0.1782\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.1325 - acc: 0.3066 - val_loss: 1.1997 - val_acc: 0.1929\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.1448 - acc: 0.2925 - val_loss: 1.2011 - val_acc: 0.2157\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.1385 - acc: 0.3122 - val_loss: 1.1980 - val_acc: 0.1952\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.1254 - acc: 0.3084 - val_loss: 1.2180 - val_acc: 0.2270\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.1346 - acc: 0.3024 - val_loss: 1.1865 - val_acc: 0.1987\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.1172 - acc: 0.3096 - val_loss: 1.2019 - val_acc: 0.2137\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 0.1180 - acc: 0.3119 - val_loss: 1.2325 - val_acc: 0.2135\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1216 - acc: 0.3233 - val_loss: 1.2052 - val_acc: 0.1962\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1213 - acc: 0.3128 - val_loss: 1.2301 - val_acc: 0.2055\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.1138 - acc: 0.3265 - val_loss: 1.2332 - val_acc: 0.2152\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.1135 - acc: 0.3188 - val_loss: 1.2489 - val_acc: 0.2072\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 0.1123 - acc: 0.3321 - val_loss: 1.2384 - val_acc: 0.2135\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 0.1128 - acc: 0.3251 - val_loss: 1.2605 - val_acc: 0.1582\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 0.1110 - acc: 0.2992 - val_loss: 1.2508 - val_acc: 0.1922\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 46s 317ms/step - loss: 0.1086 - acc: 0.3129 - val_loss: 1.2428 - val_acc: 0.2100\n",
      "--------------------------------------------------\n",
      "Beware of the dog! ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "The sky is full of stars. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "People who live in glass houses shouldn't throw stones. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "All of us were silent. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Leave it to me. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 0.1109 - acc: 0.3174 - val_loss: 1.2707 - val_acc: 0.1847\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.1174 - acc: 0.3024 - val_loss: 1.2681 - val_acc: 0.1962\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 0.1020 - acc: 0.3175 - val_loss: 1.2651 - val_acc: 0.2277\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.1007 - acc: 0.3308 - val_loss: 1.2819 - val_acc: 0.2150\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 5s 31ms/step - loss: 0.1042 - acc: 0.3148 - val_loss: 1.2745 - val_acc: 0.1832\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.1045 - acc: 0.3242 - val_loss: 1.2674 - val_acc: 0.1904\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 0.1000 - acc: 0.3032 - val_loss: 1.2699 - val_acc: 0.1882\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 0.0960 - acc: 0.3054 - val_loss: 1.3032 - val_acc: 0.2115\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 0.1022 - acc: 0.2999 - val_loss: 1.2676 - val_acc: 0.1962\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 0.1020 - acc: 0.3029 - val_loss: 1.3028 - val_acc: 0.1942\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 8s 59ms/step - loss: 0.0956 - acc: 0.3046 - val_loss: 1.2929 - val_acc: 0.2067\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.0928 - acc: 0.3136 - val_loss: 1.3000 - val_acc: 0.2130\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.0892 - acc: 0.3186 - val_loss: 1.3253 - val_acc: 0.1812\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 0.0956 - acc: 0.3158 - val_loss: 1.3296 - val_acc: 0.2185\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 0.0976 - acc: 0.3286 - val_loss: 1.2796 - val_acc: 0.1952\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.0896 - acc: 0.3029 - val_loss: 1.3166 - val_acc: 0.1952\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 0.0840 - acc: 0.3147 - val_loss: 1.3197 - val_acc: 0.2032\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 0.0834 - acc: 0.3169 - val_loss: 1.3320 - val_acc: 0.2140\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.0825 - acc: 0.3219 - val_loss: 1.3056 - val_acc: 0.1864\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.0865 - acc: 0.3102 - val_loss: 1.3499 - val_acc: 0.2117\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.0949 - acc: 0.3179 - val_loss: 1.3590 - val_acc: 0.1972\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 0.0872 - acc: 0.3361 - val_loss: 1.3291 - val_acc: 0.1779\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 8s 59ms/step - loss: 0.0889 - acc: 0.3140 - val_loss: 1.3873 - val_acc: 0.1799\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.0827 - acc: 0.3087 - val_loss: 1.3352 - val_acc: 0.2095\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.0791 - acc: 0.3280 - val_loss: 1.3582 - val_acc: 0.2152\n",
      "--------------------------------------------------\n",
      "Do you want to be rich? ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "He came back soon. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "A square has four sides. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "She is not afraid of anything. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "Come and help us. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 10\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.0779 - acc: 0.3287 - val_loss: 1.3483 - val_acc: 0.1904\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.0740 - acc: 0.3353 - val_loss: 1.3666 - val_acc: 0.2160\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.0774 - acc: 0.3340 - val_loss: 1.3527 - val_acc: 0.2060\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.0810 - acc: 0.3236 - val_loss: 1.3888 - val_acc: 0.1999\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.0911 - acc: 0.3287 - val_loss: 1.3806 - val_acc: 0.1957\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.0806 - acc: 0.3287 - val_loss: 1.3717 - val_acc: 0.2020\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 0.0737 - acc: 0.3239 - val_loss: 1.3649 - val_acc: 0.1967\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.0702 - acc: 0.3235 - val_loss: 1.3760 - val_acc: 0.2180\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 0.0694 - acc: 0.3335 - val_loss: 1.3997 - val_acc: 0.2110\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.0730 - acc: 0.3271 - val_loss: 1.3865 - val_acc: 0.2270\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 9s 59ms/step - loss: 0.0756 - acc: 0.3337 - val_loss: 1.4256 - val_acc: 0.2097\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.0778 - acc: 0.3296 - val_loss: 1.3937 - val_acc: 0.2125\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.0730 - acc: 0.3436 - val_loss: 1.4058 - val_acc: 0.2192\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.0704 - acc: 0.3423 - val_loss: 1.3898 - val_acc: 0.2087\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.0680 - acc: 0.3353 - val_loss: 1.4085 - val_acc: 0.1984\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 0.0703 - acc: 0.3260 - val_loss: 1.4091 - val_acc: 0.2087\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.0722 - acc: 0.3301 - val_loss: 1.4230 - val_acc: 0.2345\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 0.0711 - acc: 0.3430 - val_loss: 1.4443 - val_acc: 0.2117\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.0740 - acc: 0.3335 - val_loss: 1.4310 - val_acc: 0.2060\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.0678 - acc: 0.3306 - val_loss: 1.4318 - val_acc: 0.2027\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 0.0643 - acc: 0.3271 - val_loss: 1.4420 - val_acc: 0.2117\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 0.0676 - acc: 0.3281 - val_loss: 1.4318 - val_acc: 0.2080\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 0.0673 - acc: 0.3330 - val_loss: 1.4543 - val_acc: 0.2037\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.0662 - acc: 0.3365 - val_loss: 1.4526 - val_acc: 0.2082\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.0638 - acc: 0.3245 - val_loss: 1.4609 - val_acc: 0.1949\n",
      "--------------------------------------------------\n",
      "Do you have a lot of pens? ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "This apple is sweet. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "She asked him for some money. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "I don't like to go out when it's dark. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He let go of the rope. ிளல!)ு)??ழஜஜஜஜஜCஜஜC(உஉ. )C2CஇனோCோCஇCஇ னனல!கன00ல!குன00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக00லக00்்\tிளளூூலக00லக0\n",
      "--------------------------------------------------\n",
      "Iteration: 11\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 8s 59ms/step - loss: 0.0673 - acc: 0.3300 - val_loss: 1.4469 - val_acc: 0.2092\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 0.0660 - acc: 0.3193 - val_loss: 1.4518 - val_acc: 0.2092\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.0662 - acc: 0.3277 - val_loss: 1.4671 - val_acc: 0.2080\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 0.0664 - acc: 0.3306 - val_loss: 1.4593 - val_acc: 0.1869\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 0.0628 - acc: 0.3196 - val_loss: 1.4648 - val_acc: 0.1984\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 0.0654 - acc: 0.3295 - val_loss: 1.4623 - val_acc: 0.2072\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 0.0642 - acc: 0.3256 - val_loss: 1.4848 - val_acc: 0.1949\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 0.0619 - acc: 0.3291 - val_loss: 1.4781 - val_acc: 0.2017\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 10s 69ms/step - loss: 0.0613 - acc: 0.3341 - val_loss: 1.4733 - val_acc: 0.2252\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 10s 69ms/step - loss: 0.0612 - acc: 0.3381 - val_loss: 1.4628 - val_acc: 0.2155\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 9s 66ms/step - loss: 0.0693 - acc: 0.3315 - val_loss: 1.5160 - val_acc: 0.2307\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 9s 64ms/step - loss: 0.0847 - acc: 0.3410 - val_loss: 1.4236 - val_acc: 0.1939\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 9s 64ms/step - loss: 0.0647 - acc: 0.3131 - val_loss: 1.4459 - val_acc: 0.2082\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 9s 64ms/step - loss: 0.0583 - acc: 0.3333 - val_loss: 1.4670 - val_acc: 0.2227\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 0.0574 - acc: 0.3422 - val_loss: 1.4710 - val_acc: 0.2230\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 0.0569 - acc: 0.3388 - val_loss: 1.4766 - val_acc: 0.2175\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.0575 - acc: 0.3420 - val_loss: 1.4918 - val_acc: 0.2057\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 0.0600 - acc: 0.3332 - val_loss: 1.4824 - val_acc: 0.2170\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-94863930fdc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m           validation_split=0.2,callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m#prepare sample_data to test 5 samples:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "iteration=0\n",
    "\n",
    "# load weights\n",
    "print('loading the weights')\n",
    "model=load_model('char_level.h5')\n",
    "\n",
    "# estimate accuracy on whole dataset using loaded weights\n",
    "scores = model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data,verbose=0)\n",
    "print(\"%s: %.2f%%\\n\\n\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"Testing Samples\\n\"+\"-\"*50)\n",
    "for i in range(5):\n",
    "    index=np.random.randint(len(input_texts))\n",
    "    encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "    output_sequence=decode_sequence(encoded_input_sequence)\n",
    "    print(input_texts[index],output_sequence)\n",
    "print(\"-\"*50)\n",
    "\n",
    "iteration_file=\"/home/santhosh/keras/rnn/rnn_encoder_decoder/iteration_char_level.txt\"\n",
    "try:\n",
    "    file=open(iteration_file,'r')\n",
    "    last_line=file.read().split('\\n')[-2]\n",
    "    print('file_data,',last_line)\n",
    "    iteration=int(last_line.split(':')[1])\n",
    "    #print(iteration)\n",
    "    file.close()\n",
    "    \n",
    "except:\n",
    "    print('no file exist')\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights_best_char_level.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "while True:\n",
    "    print('Iteration:',iteration+1)\n",
    "    #training\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,callbacks=callbacks_list)\n",
    "    #prepare sample_data to test 5 samples:\n",
    "    print(\"-\"*50)\n",
    "    for i in range(5):\n",
    "        index=np.random.randint(len(input_texts))\n",
    "        encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "        output_sequence=decode_sequence(encoded_input_sequence)\n",
    "        print(input_texts[index],output_sequence)\n",
    "    print(\"-\"*50)\n",
    "    # Save model\n",
    "    file=open(iteration_file,'a')\n",
    "    file.write('iteration:'+str(iteration+1)+'\\n')\n",
    "    file.close()\n",
    "    iteration+=1\n",
    "    model.save('char_level.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
