{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence model for english to tamil transilation using rnn encoder and decoder ( at character level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset is downloaded from http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Input,LSTM,Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "batch_size=128\n",
    "epochs=25\n",
    "latent_dim=256\n",
    "data_path=\"/home/santhosh/keras/rnn/rnn_encoder_decoder/data/tam.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_characters=set()\n",
    "target_characters=set()\n",
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    lines=f.read().split('\\n')\n",
    "for line in lines:\n",
    "    line=line.split('\\t')\n",
    "    if(len(line)!=2):\n",
    "        continue\n",
    "    input_text,target_text=line\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text='\\t'+target_text+'\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 180\n",
      "number of unique input token: 53\n",
      "number of unique output token: 54\n",
      "Max Sequence length for inputs: 94\n",
      "Max Sequence length for outputs: 111\n"
     ]
    }
   ],
   "source": [
    "input_characters=sorted(list(input_characters))\n",
    "targer_characters=sorted(list(target_characters))\n",
    "num_encoder_tokens=len(input_characters)\n",
    "num_decoder_tokens=len(target_characters)\n",
    "max_encoder_seq_len=max([len(text) for text in input_texts])\n",
    "max_decoder_seq_len=max([len(text) for text in target_texts])\n",
    "\n",
    "print('Number of samples:',len(input_texts))\n",
    "print('number of unique input token:',num_encoder_tokens)\n",
    "print('number of unique output token:',num_decoder_tokens)\n",
    "print('Max Sequence length for inputs:',max_encoder_seq_len)\n",
    "print('Max Sequence length for outputs:',max_decoder_seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining token2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token2index=dict([(char,i) for i,char in enumerate(input_characters)])\n",
    "target_token2index=dict([(char,i) for i,char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defing encoder_input,decoder_input and decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data=np.zeros((len(input_texts),max_encoder_seq_len,num_encoder_tokens),dtype='float32')\n",
    "decoder_input_data=np.zeros((len(input_texts),max_decoder_seq_len,num_decoder_tokens),dtype='float32')\n",
    "decoder_target_data=np.zeros((len(input_texts),max_decoder_seq_len,num_decoder_tokens),dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 15,\n",
       " '\\n': 34,\n",
       " ' ': 40,\n",
       " '!': 47,\n",
       " '(': 18,\n",
       " ')': 33,\n",
       " ',': 2,\n",
       " '.': 8,\n",
       " '0': 6,\n",
       " '2': 53,\n",
       " '?': 43,\n",
       " 'C': 4,\n",
       " 'D': 39,\n",
       " 'அ': 13,\n",
       " 'ஆ': 36,\n",
       " 'இ': 25,\n",
       " 'உ': 14,\n",
       " 'ஊ': 52,\n",
       " 'எ': 31,\n",
       " 'ஏ': 26,\n",
       " 'ஒ': 1,\n",
       " 'ஓ': 9,\n",
       " 'க': 12,\n",
       " 'ங': 51,\n",
       " 'ச': 44,\n",
       " 'ஜ': 7,\n",
       " 'ஞ': 30,\n",
       " 'ட': 23,\n",
       " 'ண': 49,\n",
       " 'த': 5,\n",
       " 'ந': 10,\n",
       " 'ன': 38,\n",
       " 'ப': 16,\n",
       " 'ம': 42,\n",
       " 'ய': 41,\n",
       " 'ர': 17,\n",
       " 'ற': 50,\n",
       " 'ல': 22,\n",
       " 'ள': 48,\n",
       " 'ழ': 45,\n",
       " 'வ': 20,\n",
       " 'ஷ': 35,\n",
       " 'ஸ': 24,\n",
       " 'ா': 28,\n",
       " 'ி': 21,\n",
       " 'ீ': 29,\n",
       " 'ு': 3,\n",
       " 'ூ': 46,\n",
       " 'ெ': 27,\n",
       " 'ே': 32,\n",
       " 'ை': 37,\n",
       " 'ொ': 19,\n",
       " 'ோ': 11,\n",
       " '்': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token2index[char]]=1\n",
    "    for t,char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token2index[char]]=1\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        if t>0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i,t-1,target_token2index[char]]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an input sequence and process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Set up the decoder, using encoder_states as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model that will turn\n",
    "## `encoder_input_data` & `decoder_input_data` into `decoder_target_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token2index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token2index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token2index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_data, iteration:10\n",
      "Iteration: 11\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 10s 73ms/step - loss: 1.0362 - acc: 0.2618 - val_loss: 1.5485 - val_acc: 0.6539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3_2/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3_2/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 0.9953 - acc: 0.7787 - val_loss: 1.4390 - val_acc: 0.0470\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 0.9179 - acc: 0.0308 - val_loss: 1.3321 - val_acc: 0.6552\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 0.8333 - acc: 0.7817 - val_loss: 1.3041 - val_acc: 0.6592\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 0.8126 - acc: 0.7848 - val_loss: 1.2987 - val_acc: 0.6564\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 0.8070 - acc: 0.7836 - val_loss: 1.2953 - val_acc: 0.6564\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 0.8023 - acc: 0.7823 - val_loss: 1.2866 - val_acc: 0.6592\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 0.7965 - acc: 0.7848 - val_loss: 1.2941 - val_acc: 0.6564\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 0.7967 - acc: 0.7818 - val_loss: 1.2859 - val_acc: 0.6569\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 0.7904 - acc: 0.7835 - val_loss: 1.2866 - val_acc: 0.6637\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 0.7903 - acc: 0.7894 - val_loss: 1.2781 - val_acc: 0.6604\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 0.7894 - acc: 0.7848 - val_loss: 1.2777 - val_acc: 0.6642\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 0.7825 - acc: 0.7905 - val_loss: 1.2844 - val_acc: 0.6569\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 0.7837 - acc: 0.7835 - val_loss: 1.2795 - val_acc: 0.6574\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 0.7789 - acc: 0.7845 - val_loss: 1.3055 - val_acc: 0.6597\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.7846 - acc: 0.7865 - val_loss: 1.2870 - val_acc: 0.6624\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 0.7776 - acc: 0.7925 - val_loss: 1.2842 - val_acc: 0.6659\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 0.7766 - acc: 0.7905 - val_loss: 1.2908 - val_acc: 0.6637\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 0.7743 - acc: 0.7917 - val_loss: 1.2771 - val_acc: 0.6662\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 0.7728 - acc: 0.7834 - val_loss: 1.2833 - val_acc: 0.6491\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 0.7765 - acc: 0.7471 - val_loss: 1.2776 - val_acc: 0.6702\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 0.7632 - acc: 0.7979 - val_loss: 1.2742 - val_acc: 0.6699\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 0.7681 - acc: 0.7116 - val_loss: 1.2734 - val_acc: 0.6659\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 0.7654 - acc: 0.7922 - val_loss: 1.2637 - val_acc: 0.6739\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 0.7606 - acc: 0.7227 - val_loss: 1.2633 - val_acc: 0.6644\n",
      "--------------------------------------------------\n",
      "When does it begin? அவன்           ் ் ்் ்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்\n",
      "Do you have a lot of pens? அவன்           ் ் ் ்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்\n",
      "Friendship requires mutual trust. அவன்           ் ் ் ்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்\n",
      "Be kind to old people. அவன்           ் ் ் ்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்\n",
      "Nobody speaks to me. அவன்           ் ் ் ்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்\n",
      "--------------------------------------------------\n",
      "Iteration: 12\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 0.7601 - acc: 0.7900 - val_loss: 1.2790 - val_acc: 0.6714\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 5s 32ms/step - loss: 0.7608 - acc: 0.7950 - val_loss: 1.2588 - val_acc: 0.6677\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.7511 - acc: 0.7946 - val_loss: 1.2539 - val_acc: 0.6749\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.7533 - acc: 0.7965 - val_loss: 1.2546 - val_acc: 0.6719\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.7549 - acc: 0.7638 - val_loss: 1.2618 - val_acc: 0.6694\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.7515 - acc: 0.7803 - val_loss: 1.2439 - val_acc: 0.6699\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.7468 - acc: 0.7934 - val_loss: 1.2568 - val_acc: 0.6694\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.7450 - acc: 0.7965 - val_loss: 1.2636 - val_acc: 0.6684\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.7392 - acc: 0.7238 - val_loss: 1.2512 - val_acc: 0.6639\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.7498 - acc: 0.7947 - val_loss: 1.2410 - val_acc: 0.6757\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.7346 - acc: 0.8024 - val_loss: 1.2549 - val_acc: 0.6769\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.7347 - acc: 0.7999 - val_loss: 1.2422 - val_acc: 0.6817\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.7381 - acc: 0.7809 - val_loss: 1.2192 - val_acc: 0.6822\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.7290 - acc: 0.7949 - val_loss: 1.2369 - val_acc: 0.0936\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.7224 - acc: 0.1504 - val_loss: 1.2158 - val_acc: 0.6879\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.7188 - acc: 0.7337 - val_loss: 1.2021 - val_acc: 0.6762\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 0.7161 - acc: 0.7290 - val_loss: 1.2234 - val_acc: 0.6767\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7172 - acc: 0.8052 - val_loss: 1.2112 - val_acc: 0.6774\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.7050 - acc: 0.8047 - val_loss: 1.2137 - val_acc: 0.6779\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.7043 - acc: 0.8075 - val_loss: 1.2176 - val_acc: 0.6822\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.7060 - acc: 0.8096 - val_loss: 1.2228 - val_acc: 0.0951\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.7005 - acc: 0.1603 - val_loss: 1.1894 - val_acc: 0.1479\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6858 - acc: 0.2862 - val_loss: 1.1938 - val_acc: 0.1039\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.6836 - acc: 0.1994 - val_loss: 1.2222 - val_acc: 0.0973\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.6908 - acc: 0.1922 - val_loss: 1.1905 - val_acc: 0.6949\n",
      "--------------------------------------------------\n",
      "He got a lot of money. அவன்  ன் ு ு ு ு் ு்் ு்்\n",
      "\n",
      "Do you want to be rich? அவன்  ன் ு ு ு ு் ு்் ு்்\n",
      "\n",
      "He began to run. அவன்  ன் ு ு ு ு் ு்் ு்்\n",
      "\n",
      "They made fun of Mary. அவன்  ன் ு ு ு ு் ு்் ு்்\n",
      "\n",
      "She boiled the eggs. அவன்  ன் ு ு ு ு் ு்் ு்்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 13\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6808 - acc: 0.8149 - val_loss: 1.1634 - val_acc: 0.6872\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.6728 - acc: 0.8078 - val_loss: 1.1704 - val_acc: 0.1049\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6744 - acc: 0.1766 - val_loss: 1.1495 - val_acc: 0.1204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6699 - acc: 0.1970 - val_loss: 1.1443 - val_acc: 0.7015\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.6697 - acc: 0.7371 - val_loss: 1.1567 - val_acc: 0.6889\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6703 - acc: 0.7357 - val_loss: 1.1700 - val_acc: 0.6564\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6601 - acc: 0.7950 - val_loss: 1.1274 - val_acc: 0.6722\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6504 - acc: 0.8025 - val_loss: 1.1455 - val_acc: 0.1224\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.6462 - acc: 0.1994 - val_loss: 1.1494 - val_acc: 0.1256\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.6451 - acc: 0.2033 - val_loss: 1.1278 - val_acc: 0.6882\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6369 - acc: 0.7406 - val_loss: 1.1365 - val_acc: 0.6829\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6426 - acc: 0.7358 - val_loss: 1.1035 - val_acc: 0.6987\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6375 - acc: 0.7339 - val_loss: 1.1146 - val_acc: 0.1026\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6402 - acc: 0.1617 - val_loss: 1.1135 - val_acc: 0.6892\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6251 - acc: 0.8159 - val_loss: 1.1038 - val_acc: 0.6927\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6193 - acc: 0.7477 - val_loss: 1.0964 - val_acc: 0.6942\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6180 - acc: 0.7423 - val_loss: 1.0960 - val_acc: 0.6789\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6166 - acc: 0.8051 - val_loss: 1.0921 - val_acc: 0.1194\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6100 - acc: 0.1903 - val_loss: 1.0950 - val_acc: 0.1494\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.6162 - acc: 0.2473 - val_loss: 1.0711 - val_acc: 0.6944\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6046 - acc: 0.8189 - val_loss: 1.0890 - val_acc: 0.6797\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.6003 - acc: 0.8096 - val_loss: 1.0874 - val_acc: 0.6969\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.5984 - acc: 0.8201 - val_loss: 1.0639 - val_acc: 0.6989\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5942 - acc: 0.7458 - val_loss: 1.0738 - val_acc: 0.6817\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5983 - acc: 0.8108 - val_loss: 1.0446 - val_acc: 0.6974\n",
      "--------------------------------------------------\n",
      "I'm taller than you. அவன் பன் புட் பிட் பிட் பிட் பிட் துட்\n",
      "\n",
      "She is kind. அவன் பன் புட் பிட் பிட் பிட் பிட் துட்\n",
      "\n",
      "Don't listen to her. அவன் பன் புட் பிட் பிட் பிட் பிட் துட்\n",
      "\n",
      "She got married to him. அவன் பன் புட் பிட் பிட் பிட் பிட் துட்\n",
      "\n",
      "He asked us to help him. அவன் பன் புட் பிட் பிட் பிட் பிட் துட்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 14\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5921 - acc: 0.7768 - val_loss: 1.0694 - val_acc: 0.1239\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.6012 - acc: 0.1038 - val_loss: 1.0649 - val_acc: 0.6732\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.5863 - acc: 0.7335 - val_loss: 1.0506 - val_acc: 0.7035\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.5770 - acc: 0.8244 - val_loss: 1.0607 - val_acc: 0.6992\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5754 - acc: 0.8233 - val_loss: 1.0506 - val_acc: 0.6987\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.5716 - acc: 0.7486 - val_loss: 1.0679 - val_acc: 0.6897\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.5869 - acc: 0.7384 - val_loss: 1.0337 - val_acc: 0.7007\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.5686 - acc: 0.7561 - val_loss: 1.0262 - val_acc: 0.7080\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5620 - acc: 0.8235 - val_loss: 1.0284 - val_acc: 0.7017\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5615 - acc: 0.7539 - val_loss: 1.0507 - val_acc: 0.6374\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.5655 - acc: 0.7707 - val_loss: 1.0272 - val_acc: 0.7057\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.5577 - acc: 0.8281 - val_loss: 1.0125 - val_acc: 0.6734\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.5541 - acc: 0.7231 - val_loss: 1.0369 - val_acc: 0.1171\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.5648 - acc: 0.1774 - val_loss: 1.0309 - val_acc: 0.1349\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5479 - acc: 0.1961 - val_loss: 1.0323 - val_acc: 0.1399\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.5477 - acc: 0.1978 - val_loss: 1.0112 - val_acc: 0.6942\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5440 - acc: 0.8031 - val_loss: 0.9926 - val_acc: 0.6867\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.5383 - acc: 0.8115 - val_loss: 1.0119 - val_acc: 0.7095\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5426 - acc: 0.7614 - val_loss: 1.0202 - val_acc: 0.6451\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.5510 - acc: 0.7770 - val_loss: 1.0024 - val_acc: 0.6401\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.5324 - acc: 0.7824 - val_loss: 0.9799 - val_acc: 0.7160\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.5376 - acc: 0.8259 - val_loss: 0.9759 - val_acc: 0.6819\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.5316 - acc: 0.7850 - val_loss: 0.9855 - val_acc: 0.1647\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.5273 - acc: 0.2068 - val_loss: 0.9851 - val_acc: 0.6089\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.5257 - acc: 0.7454 - val_loss: 1.0214 - val_acc: 0.1299\n",
      "--------------------------------------------------\n",
      "I want to be a pilot in the future. அவன் அவன் வரும் பிடிட்\n",
      "\n",
      "Who is he? அவன் அவன் வரும் பிடிட்\n",
      "\n",
      "I'm trying to sleep. அவன் அவன் வரும் பிடிட்\n",
      "\n",
      "Go and wake Mary up. அவன் அவன் வரும் பிடிட்\n",
      "\n",
      "Speak slowly and clearly. அவன் அவன் படம் பாட்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 15\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5252 - acc: 0.1886 - val_loss: 0.9771 - val_acc: 0.1699\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.5172 - acc: 0.2591 - val_loss: 0.9833 - val_acc: 0.2087\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.5147 - acc: 0.2561 - val_loss: 1.0113 - val_acc: 0.2513\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.5281 - acc: 0.2635 - val_loss: 0.9983 - val_acc: 0.2783\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5153 - acc: 0.3589 - val_loss: 0.9734 - val_acc: 0.1787\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.5066 - acc: 0.2319 - val_loss: 0.9770 - val_acc: 0.3108\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.5048 - acc: 0.2952 - val_loss: 0.9778 - val_acc: 0.3691\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5053 - acc: 0.4503 - val_loss: 0.9664 - val_acc: 0.7020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.5141 - acc: 0.7927 - val_loss: 0.9802 - val_acc: 0.6917\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 0.5053 - acc: 0.7426 - val_loss: 0.9772 - val_acc: 0.6161\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.4949 - acc: 0.7616 - val_loss: 0.9972 - val_acc: 0.1361\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 4s 31ms/step - loss: 0.5078 - acc: 0.1918 - val_loss: 0.9740 - val_acc: 0.1419\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.4977 - acc: 0.1985 - val_loss: 0.9794 - val_acc: 0.2665\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4913 - acc: 0.3148 - val_loss: 0.9941 - val_acc: 0.6667\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.4962 - acc: 0.7961 - val_loss: 0.9698 - val_acc: 0.5936\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.4873 - acc: 0.7549 - val_loss: 0.9607 - val_acc: 0.7042\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4825 - acc: 0.7581 - val_loss: 0.9681 - val_acc: 0.6922\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4991 - acc: 0.7401 - val_loss: 0.9635 - val_acc: 0.6451\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.4856 - acc: 0.7619 - val_loss: 0.9448 - val_acc: 0.5668\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.4785 - acc: 0.6971 - val_loss: 0.9422 - val_acc: 0.4730\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.4866 - acc: 0.5522 - val_loss: 0.9407 - val_acc: 0.1749\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.4745 - acc: 0.1543 - val_loss: 0.9671 - val_acc: 0.1349\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.4782 - acc: 0.1297 - val_loss: 0.9537 - val_acc: 0.2270\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4719 - acc: 0.2190 - val_loss: 0.9588 - val_acc: 0.1624\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4699 - acc: 0.2124 - val_loss: 0.9446 - val_acc: 0.1519\n",
      "--------------------------------------------------\n",
      "She danced with him. அவள் அவனிட் து விட்து தெருக்கிறேன்\n",
      "\n",
      "Tom runs very fast. அவள் அவனிட் து விட்து வேட்டிடிட்து\n",
      "\n",
      "He asked us to help him. அவள் அவனிட் து விட்து வேட்டிடிட்து\n",
      "\n",
      "Do I have to study? அவள் அவனிட் து விட்து வேட்டிடிட்து\n",
      "\n",
      "Don't drink and drive. அவள் அவனிட் து விட்து வேட்டிடிட்து\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 16\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4754 - acc: 0.1348 - val_loss: 0.9649 - val_acc: 0.1466\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4689 - acc: 0.1316 - val_loss: 0.9438 - val_acc: 0.4712\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4631 - acc: 0.5405 - val_loss: 0.9745 - val_acc: 0.1562\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4668 - acc: 0.1628 - val_loss: 0.9422 - val_acc: 0.1557\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4640 - acc: 0.1378 - val_loss: 0.9348 - val_acc: 0.7192\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4662 - acc: 0.7502 - val_loss: 0.9626 - val_acc: 0.1439\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4541 - acc: 0.1501 - val_loss: 0.9488 - val_acc: 0.1484\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4523 - acc: 0.1365 - val_loss: 0.9612 - val_acc: 0.1849\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4591 - acc: 0.1994 - val_loss: 0.9457 - val_acc: 0.1524\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4475 - acc: 0.1568 - val_loss: 0.9578 - val_acc: 0.1627\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.4491 - acc: 0.1637 - val_loss: 0.9303 - val_acc: 0.3764\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.4468 - acc: 0.3772 - val_loss: 0.9337 - val_acc: 0.1749\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.4528 - acc: 0.2160 - val_loss: 0.9266 - val_acc: 0.5385\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4390 - acc: 0.5770 - val_loss: 0.9216 - val_acc: 0.1524\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4418 - acc: 0.1418 - val_loss: 0.9235 - val_acc: 0.2728\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4355 - acc: 0.2768 - val_loss: 0.9475 - val_acc: 0.1469\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4411 - acc: 0.1391 - val_loss: 0.9415 - val_acc: 0.5603\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4398 - acc: 0.5978 - val_loss: 0.9481 - val_acc: 0.1466\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4360 - acc: 0.2090 - val_loss: 0.9283 - val_acc: 0.1532\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4252 - acc: 0.1645 - val_loss: 0.9655 - val_acc: 0.1464\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4299 - acc: 0.1654 - val_loss: 0.9581 - val_acc: 0.1456\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4296 - acc: 0.1405 - val_loss: 0.9380 - val_acc: 0.1539\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4322 - acc: 0.1458 - val_loss: 0.9320 - val_acc: 0.1759\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.4211 - acc: 0.1699 - val_loss: 0.9468 - val_acc: 0.1466\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4310 - acc: 0.1834 - val_loss: 0.9404 - val_acc: 0.1562\n",
      "--------------------------------------------------\n",
      "Do you have a lot of pens? அவள் அவனுக்கு நிச்சசயம்\n",
      "\n",
      "I want to go abroad. அவள் அவனுக்கு நிச்சசயம்\n",
      "\n",
      "Keep to the right. அவள் அவனுக்கு நிச்சசயம்\n",
      "\n",
      "I live on the bottom floor. அவள் அவனுக்கு நிச்சசயம்\n",
      "\n",
      "Tom runs very fast. அவள் அவனுக்கு நிச்சசயம்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 17\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4125 - acc: 0.1577 - val_loss: 0.9468 - val_acc: 0.1522\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4247 - acc: 0.1514 - val_loss: 0.9585 - val_acc: 0.1927\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4315 - acc: 0.1933 - val_loss: 0.9325 - val_acc: 0.1577\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4132 - acc: 0.1468 - val_loss: 0.9234 - val_acc: 0.1854\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4180 - acc: 0.1649 - val_loss: 0.9146 - val_acc: 0.1614\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4162 - acc: 0.1472 - val_loss: 0.9518 - val_acc: 0.1449\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4100 - acc: 0.1478 - val_loss: 0.9364 - val_acc: 0.1512\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4043 - acc: 0.1582 - val_loss: 0.9483 - val_acc: 0.1542\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4026 - acc: 0.1544 - val_loss: 0.9442 - val_acc: 0.3869\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4075 - acc: 0.3888 - val_loss: 0.9264 - val_acc: 0.1927\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4002 - acc: 0.2024 - val_loss: 0.9252 - val_acc: 0.1607\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4091 - acc: 0.1481 - val_loss: 0.9186 - val_acc: 0.1664\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.4035 - acc: 0.1675 - val_loss: 0.9352 - val_acc: 0.1557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3939 - acc: 0.1530 - val_loss: 0.9382 - val_acc: 0.1522\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.4010 - acc: 0.1488 - val_loss: 0.9310 - val_acc: 0.4257\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3940 - acc: 0.4515 - val_loss: 0.9386 - val_acc: 0.1699\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.3941 - acc: 0.1642 - val_loss: 0.9393 - val_acc: 0.1552\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3932 - acc: 0.1508 - val_loss: 0.9383 - val_acc: 0.1617\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3824 - acc: 0.1646 - val_loss: 0.9580 - val_acc: 0.1552\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3927 - acc: 0.1542 - val_loss: 0.9352 - val_acc: 0.1672\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3949 - acc: 0.1640 - val_loss: 0.9272 - val_acc: 0.1564\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3853 - acc: 0.1601 - val_loss: 0.9305 - val_acc: 0.1609\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3788 - acc: 0.1601 - val_loss: 0.9393 - val_acc: 0.1589\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3748 - acc: 0.1632 - val_loss: 0.9639 - val_acc: 0.1549\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3745 - acc: 0.1571 - val_loss: 0.9529 - val_acc: 0.1524\n",
      "--------------------------------------------------\n",
      "She glanced through the magazine. அவன் அவனிடம் பிடிடு வேண்டு வெருக்கிறேன்\n",
      "\n",
      "I told him to come. அவன் அவனிடம் பிடியாதா?\n",
      "\n",
      "My younger sister got married in her teens. அவன் அவனிடம் பிடிடு வேண்டு வெருக்கிறேன்\n",
      "\n",
      "Keep to the right. அவன் அவனிடம் பிடியாதா?\n",
      "\n",
      "Don't lie to me. அவன் அவனிடம் பிடியாதா?\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 18\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3827 - acc: 0.1535 - val_loss: 0.9354 - val_acc: 0.1567\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3705 - acc: 0.1568 - val_loss: 0.9454 - val_acc: 0.1929\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3793 - acc: 0.1905 - val_loss: 0.9477 - val_acc: 0.1709\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3723 - acc: 0.1782 - val_loss: 0.9475 - val_acc: 0.1924\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3683 - acc: 0.1980 - val_loss: 0.9459 - val_acc: 0.1907\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3645 - acc: 0.1959 - val_loss: 0.9566 - val_acc: 0.1554\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3712 - acc: 0.1593 - val_loss: 0.9426 - val_acc: 0.1667\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3604 - acc: 0.1760 - val_loss: 0.9328 - val_acc: 0.1554\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3687 - acc: 0.1616 - val_loss: 0.9328 - val_acc: 0.1607\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3553 - acc: 0.1700 - val_loss: 0.9442 - val_acc: 0.1637\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3588 - acc: 0.1692 - val_loss: 0.9589 - val_acc: 0.1554\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3656 - acc: 0.1627 - val_loss: 0.9688 - val_acc: 0.1537\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3544 - acc: 0.1683 - val_loss: 0.9356 - val_acc: 0.1632\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3440 - acc: 0.1739 - val_loss: 0.9521 - val_acc: 0.1687\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3507 - acc: 0.1794 - val_loss: 0.9478 - val_acc: 0.1609\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3475 - acc: 0.1663 - val_loss: 0.9448 - val_acc: 0.1539\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3431 - acc: 0.1747 - val_loss: 0.9502 - val_acc: 0.1559\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3435 - acc: 0.1660 - val_loss: 0.9504 - val_acc: 0.2100\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3433 - acc: 0.2294 - val_loss: 0.9379 - val_acc: 0.1619\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3369 - acc: 0.1709 - val_loss: 0.9488 - val_acc: 0.2325\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3479 - acc: 0.2444 - val_loss: 0.9397 - val_acc: 0.1594\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3361 - acc: 0.1806 - val_loss: 0.9583 - val_acc: 0.1614\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3396 - acc: 0.1720 - val_loss: 0.9601 - val_acc: 0.1929\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3301 - acc: 0.2173 - val_loss: 0.9558 - val_acc: 0.1687\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3328 - acc: 0.1848 - val_loss: 0.9485 - val_acc: 0.1732\n",
      "--------------------------------------------------\n",
      "Come and help us. அவன் அவனிடம் படிதாதாள்\n",
      "\n",
      "I'm trying to sleep. அவன் அவனிடம் படிதாதாள்\n",
      "\n",
      "Come and help us. அவன் அவனிடம் படிதாதாள்\n",
      "\n",
      "When is your birthday? அவன் அவனிடம் படிதாதாள்\n",
      "\n",
      "When did you come to Japan? அவன் அவனிடம் படிதாதாள்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 19\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3206 - acc: 0.1903 - val_loss: 0.9802 - val_acc: 0.1504\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3380 - acc: 0.1758 - val_loss: 0.9880 - val_acc: 0.1484\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3352 - acc: 0.1700 - val_loss: 0.9569 - val_acc: 0.1597\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3194 - acc: 0.1826 - val_loss: 0.9645 - val_acc: 0.1522\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3193 - acc: 0.1752 - val_loss: 0.9544 - val_acc: 0.1584\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3243 - acc: 0.1714 - val_loss: 0.9564 - val_acc: 0.1947\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3155 - acc: 0.2070 - val_loss: 0.9810 - val_acc: 0.1534\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.3196 - acc: 0.1757 - val_loss: 0.9663 - val_acc: 0.1694\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3144 - acc: 0.1911 - val_loss: 0.9533 - val_acc: 0.1627\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3234 - acc: 0.1911 - val_loss: 0.9794 - val_acc: 0.1749\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3158 - acc: 0.2012 - val_loss: 0.9718 - val_acc: 0.1672\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3084 - acc: 0.1969 - val_loss: 0.9638 - val_acc: 0.1829\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3075 - acc: 0.2116 - val_loss: 0.9575 - val_acc: 0.1844\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3001 - acc: 0.2211 - val_loss: 0.9740 - val_acc: 0.1509\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3056 - acc: 0.1805 - val_loss: 0.9690 - val_acc: 0.2035\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3063 - acc: 0.2370 - val_loss: 0.9718 - val_acc: 0.1667\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2957 - acc: 0.1945 - val_loss: 0.9685 - val_acc: 0.1657\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2990 - acc: 0.1969 - val_loss: 0.9640 - val_acc: 0.1699\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 3s 18ms/step - loss: 0.3023 - acc: 0.1935 - val_loss: 0.9667 - val_acc: 0.1762\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2968 - acc: 0.2063 - val_loss: 0.9644 - val_acc: 0.1912\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2966 - acc: 0.2232 - val_loss: 0.9849 - val_acc: 0.1554\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2983 - acc: 0.1862 - val_loss: 0.9656 - val_acc: 0.1779\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2958 - acc: 0.2034 - val_loss: 0.9655 - val_acc: 0.1767\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2856 - acc: 0.2005 - val_loss: 0.9594 - val_acc: 0.1792\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2915 - acc: 0.2127 - val_loss: 0.9808 - val_acc: 0.1597\n",
      "--------------------------------------------------\n",
      "It's the third biggest city of Serbia. அவன் அவனுக்கு நிச்சயம்கிக்கள்\n",
      "\n",
      "He began to run. அவன் அவனுக்கு நிச்சயம்கிக்கள்\n",
      "\n",
      "Do you have any gum? அவன் அவனுக்கு நிச்சயம்கிக்கள்\n",
      "\n",
      "Be kind to old people. அவன் அவனுக்கு நிச்சயம்கிக்கள்\n",
      "\n",
      "This apple is sweet. அவன் அவனுக்கு நிச்சயம்கிக்கேன்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 20\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2772 - acc: 0.1983 - val_loss: 0.9867 - val_acc: 0.1649\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2743 - acc: 0.1992 - val_loss: 1.0052 - val_acc: 0.1579\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2792 - acc: 0.1923 - val_loss: 0.9903 - val_acc: 0.2160\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2937 - acc: 0.2451 - val_loss: 1.0129 - val_acc: 0.1572\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2808 - acc: 0.1882 - val_loss: 1.0028 - val_acc: 0.1772\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2710 - acc: 0.2167 - val_loss: 0.9936 - val_acc: 0.1699\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2736 - acc: 0.2133 - val_loss: 1.0001 - val_acc: 0.1879\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2840 - acc: 0.2222 - val_loss: 1.0016 - val_acc: 0.2047\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2691 - acc: 0.2551 - val_loss: 1.0134 - val_acc: 0.1812\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2747 - acc: 0.2224 - val_loss: 0.9969 - val_acc: 0.1947\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2706 - acc: 0.2356 - val_loss: 0.9876 - val_acc: 0.1967\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2575 - acc: 0.2518 - val_loss: 0.9972 - val_acc: 0.1547\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2705 - acc: 0.1955 - val_loss: 1.0260 - val_acc: 0.1522\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2661 - acc: 0.1974 - val_loss: 1.0016 - val_acc: 0.1684\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2569 - acc: 0.2050 - val_loss: 1.0138 - val_acc: 0.2092\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2715 - acc: 0.2452 - val_loss: 1.0019 - val_acc: 0.1654\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.2646 - acc: 0.2042 - val_loss: 1.0110 - val_acc: 0.1847\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.2603 - acc: 0.2287 - val_loss: 1.0153 - val_acc: 0.1984\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.2560 - acc: 0.2397 - val_loss: 1.0151 - val_acc: 0.1584\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.2398 - acc: 0.2100 - val_loss: 1.0313 - val_acc: 0.1944\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.2535 - acc: 0.2443 - val_loss: 1.0233 - val_acc: 0.1774\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.2516 - acc: 0.2220 - val_loss: 1.0301 - val_acc: 0.1609\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2463 - acc: 0.2058 - val_loss: 1.0274 - val_acc: 0.1564\n",
      "Epoch 24/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2411 - acc: 0.2079 - val_loss: 1.0229 - val_acc: 0.1597\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.2420 - acc: 0.2087 - val_loss: 1.0643 - val_acc: 0.1709\n",
      "--------------------------------------------------\n",
      "She sat next to me. அவன் அவனுக் நிச்சயம்\n",
      "\n",
      "Do I have to study? அவன் அவனுக் நிச்சயம்\n",
      "\n",
      "It may rain. அவன் அவனுக் நிச்சயம்\n",
      "\n",
      "She went out of the room. அவன் அவனுக் நிச்சயம்\n",
      "\n",
      "He is afraid of snakes. அவன் அவனுக் நிச்சயம்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 21\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 0.2444 - acc: 0.2276 - val_loss: 1.0512 - val_acc: 0.1534\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.2382 - acc: 0.2098 - val_loss: 1.0476 - val_acc: 0.1659\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2464 - acc: 0.2162 - val_loss: 1.0568 - val_acc: 0.1804\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2516 - acc: 0.2315 - val_loss: 1.0424 - val_acc: 0.1777\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2284 - acc: 0.2406 - val_loss: 1.0475 - val_acc: 0.1789\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.2252 - acc: 0.2394 - val_loss: 1.0479 - val_acc: 0.1909\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2345 - acc: 0.2367 - val_loss: 1.0708 - val_acc: 0.1534\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.2388 - acc: 0.2133 - val_loss: 1.0514 - val_acc: 0.1699\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.2328 - acc: 0.2249 - val_loss: 1.0418 - val_acc: 0.1714\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2213 - acc: 0.2300 - val_loss: 1.0530 - val_acc: 0.1772\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2178 - acc: 0.2362 - val_loss: 1.0635 - val_acc: 0.1817\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2259 - acc: 0.2340 - val_loss: 1.0790 - val_acc: 0.1534\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2268 - acc: 0.2136 - val_loss: 1.0617 - val_acc: 0.1689\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2277 - acc: 0.2187 - val_loss: 1.0585 - val_acc: 0.1757\n",
      "Epoch 15/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2230 - acc: 0.2347 - val_loss: 1.0797 - val_acc: 0.1812\n",
      "Epoch 16/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2374 - acc: 0.2302 - val_loss: 1.0545 - val_acc: 0.1584\n",
      "Epoch 17/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2128 - acc: 0.2147 - val_loss: 1.0424 - val_acc: 0.1799\n",
      "Epoch 18/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.2097 - acc: 0.2404 - val_loss: 1.0759 - val_acc: 0.1604\n",
      "Epoch 19/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.2209 - acc: 0.2261 - val_loss: 1.0956 - val_acc: 0.1559\n",
      "Epoch 20/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.2129 - acc: 0.2188 - val_loss: 1.0719 - val_acc: 0.1657\n",
      "Epoch 21/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.2046 - acc: 0.2284 - val_loss: 1.0630 - val_acc: 0.1817\n",
      "Epoch 22/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.2067 - acc: 0.2449 - val_loss: 1.0917 - val_acc: 0.1609\n",
      "Epoch 23/25\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.2032 - acc: 0.2297 - val_loss: 1.0926 - val_acc: 0.1544\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 3s 21ms/step - loss: 0.2001 - acc: 0.2289 - val_loss: 1.0843 - val_acc: 0.1634\n",
      "Epoch 25/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.1988 - acc: 0.2376 - val_loss: 1.0895 - val_acc: 0.1692\n",
      "--------------------------------------------------\n",
      "He has a lot of money. அவள் அவனுக்கு நிரும் செய்திற்குக்கே இருக்கின்\n",
      "\n",
      "I'm short of money. அவள் அவனுக்கு நிரும் செய்திற்குக்கே இருக்கின்\n",
      "\n",
      "It's been a long time since I've heard anyone use that word. அவள் அவனுக்கு நிரும் செய்திற்குக்கே இருக்கின்\n",
      "\n",
      "The price of eggs is going up. அவள் அவனுக்கு நிரும் செய்திற்குக்கே இருக்கின்\n",
      "\n",
      "Raise your hand. அவள் அவனுக்கு நிரும் செய்திற்குக்கே இருக்கின்\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration: 22\n",
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.2009 - acc: 0.2458 - val_loss: 1.1068 - val_acc: 0.1599\n",
      "Epoch 2/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.1974 - acc: 0.2326 - val_loss: 1.1074 - val_acc: 0.1837\n",
      "Epoch 3/25\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 0.2215 - acc: 0.2386 - val_loss: 1.0775 - val_acc: 0.1617\n",
      "Epoch 4/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.2057 - acc: 0.2329 - val_loss: 1.0739 - val_acc: 0.1647\n",
      "Epoch 5/25\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 0.2020 - acc: 0.2282 - val_loss: 1.0857 - val_acc: 0.1799\n",
      "Epoch 6/25\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.1885 - acc: 0.2529 - val_loss: 1.1015 - val_acc: 0.1947\n",
      "Epoch 7/25\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.1936 - acc: 0.2659 - val_loss: 1.1010 - val_acc: 0.1962\n",
      "Epoch 8/25\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1958 - acc: 0.2708 - val_loss: 1.1005 - val_acc: 0.1557\n",
      "Epoch 9/25\n",
      "144/144 [==============================] - 4s 31ms/step - loss: 0.1925 - acc: 0.2265 - val_loss: 1.1158 - val_acc: 0.1429\n",
      "Epoch 10/25\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1890 - acc: 0.2231 - val_loss: 1.1232 - val_acc: 0.1677\n",
      "Epoch 11/25\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.1902 - acc: 0.2471 - val_loss: 1.1180 - val_acc: 0.1594\n",
      "Epoch 12/25\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.1840 - acc: 0.2380 - val_loss: 1.1092 - val_acc: 0.1589\n",
      "Epoch 13/25\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.1845 - acc: 0.2356 - val_loss: 1.1119 - val_acc: 0.1607\n",
      "Epoch 14/25\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 0.1894 - acc: 0.2292 - val_loss: 1.1388 - val_acc: 0.1569\n",
      "Epoch 15/25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iteration=0\n",
    "\"\"\"\n",
    "# load weights\n",
    "print('loading the weights')\n",
    "model=load_model('char_level.h5')\n",
    "\n",
    "# estimate accuracy on whole dataset using loaded weights\n",
    "scores = model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data,verbose=0)\n",
    "print(\"%s: %.2f%%\\n\\n\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"Testing Samples\\n\"+\"-\"*50)\n",
    "for i in range(5):\n",
    "    index=np.random.randint(len(input_texts))\n",
    "    encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "    output_sequence=decode_sequence(encoded_input_sequence)\n",
    "    print(input_texts[index],output_sequence)\n",
    "print(\"-\"*50)\n",
    "\"\"\"\n",
    "iteration_file=\"/home/santhosh/keras/rnn/rnn_encoder_decoder/iteration_char_level.txt\"\n",
    "try:\n",
    "    file=open(iteration_file,'r')\n",
    "    last_line=file.read().split('\\n')[-2]\n",
    "    print('file_data,',last_line)\n",
    "    iteration=int(last_line.split(':')[1])\n",
    "    #print(iteration)\n",
    "    file.close()\n",
    "    \n",
    "except:\n",
    "    print('no file exist')\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights_best_char_level.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "while True:\n",
    "    print('Iteration:',iteration+1)\n",
    "    #training\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,callbacks=callbacks_list)\n",
    "    #prepare sample_data to test 5 samples:\n",
    "    print(\"-\"*50)\n",
    "    for i in range(5):\n",
    "        index=np.random.randint(len(input_texts))\n",
    "        encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "        output_sequence=decode_sequence(encoded_input_sequence)\n",
    "        print(input_texts[index],output_sequence)\n",
    "    print(\"-\"*50)\n",
    "    # Save model\n",
    "    file=open(iteration_file,'a')\n",
    "    file.write('iteration:'+str(iteration+1)+'\\n')\n",
    "    file.close()\n",
    "    iteration+=1\n",
    "    model.save('char_level.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
