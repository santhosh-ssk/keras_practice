{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from keras.datasets import mnist\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "print(x_train.shape[0], 'train samples','shape',x_train.shape)\n",
    "print(x_test.shape[0], 'test samples',x_test.shape)\n",
    "\n",
    "#reshaping the x_test,x_train to 60000*784\n",
    "reshape=784\n",
    "x_train=x_train.reshape(60000,784)\n",
    "x_test=x_test.reshape(10000,784)\n",
    "print(x_train.shape[0], 'train samples','shape',x_train.shape)\n",
    "print(x_test.shape[0], 'test samples',x_test.shape)\n",
    "\n",
    "#change int to float\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#normalize the traing and testing data\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255\n",
    "\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "from keras.utils import np_utils\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "print('before converting',y_test[0])\n",
    "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "print( 'After converting',y_test[0])\n",
    "\n",
    "#we now create a model(with no hidden layers) with 10 neurans(since we use 10 class labels),and input is 784(features)\n",
    "#our activation function is softmax\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "model=Sequential()\n",
    "model.add(Dense(NB_CLASSES,input_shape=(reshape,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "#now we need compile the model,with optimser as SGD,loss function as  Categorical cross-entropy and to evaluate we use accuracy metrics\n",
    "from keras.optimizers import SGD\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#now we train our model with epochs=200, and batch size as 128 and validation_split=0.2,verbose=1(progress bar)\n",
    "history=model.fit(x_train,y_train,epochs=200,batch_size=128,validation_split=0.2,verbose=1)\n",
    "\n",
    "#finally we evaluate the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
