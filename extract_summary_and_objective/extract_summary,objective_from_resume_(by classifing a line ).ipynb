{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence model to extract summary,objective from resume (input: resume line by line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 207 resumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import csv,os\n",
    "import collections\n",
    "from keras.models import load_model,Sequential\n",
    "from keras.layers import Input,LSTM,Dense,Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "batch_size=128\n",
    "epochs=20\n",
    "latent_dim=128\n",
    "data_path=\"/home/santhosh/resumes_folder/custom_annotator/annotator-server/static/files/Data_Tracter_Resumes_in_TXT/csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resumes=[]\n",
    "output_summary=[]\n",
    "input_tokens=collections.Counter()\n",
    "output_tokens=set()\n",
    "files=os.listdir(data_path)\n",
    "count=0\n",
    "for file in files[:50]:\n",
    "    with open(data_path+'/'+file,'r') as csv_file:\n",
    "        reader=csv.reader(csv_file)\n",
    "        count=0\n",
    "        for Input_text,output_text in reader:\n",
    "            Input_text=Input_text.strip().lower()\n",
    "            Input_text=Input_text\n",
    "            \n",
    "            input_resumes.append(Input_text)\n",
    "            output_summary.append(output_text)\n",
    "            \n",
    "            for word in Input_text.split():\n",
    "                if word not in input_tokens:\n",
    "                    input_tokens[word]+=1\n",
    "            for word in output_text.split():\n",
    "                if word not in output_tokens:\n",
    "                    output_tokens.add(word)\n",
    "            if count==50:\n",
    "                break\n",
    "            count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5179\n",
      "Number of samples: 2510\n",
      "number of unique input token: 4000\n",
      "number of unique output token: 2\n",
      "Max Sequence length for inputs: 24\n",
      "Max Sequence length for outputs: 1\n"
     ]
    }
   ],
   "source": [
    "print(len(input_tokens))\n",
    "num_encoder_tokens=min(len(input_tokens),4000)\n",
    "input_tokens=[word for word,count in input_tokens.most_common(num_encoder_tokens-1)]\n",
    "input_tokens=sorted(list(input_tokens))\n",
    "output_tokens=sorted(list(output_tokens))\n",
    "num_decoder_tokens=len(output_tokens)\n",
    "max_encoder_seq_len=max([len(text.split()) for text in input_resumes])\n",
    "max_decoder_seq_len=max([len(text.split()) for text in output_summary])\n",
    "\n",
    "print('Number of samples:',len(input_resumes))\n",
    "print('number of unique input token:',num_encoder_tokens)\n",
    "print('number of unique output token:',num_decoder_tokens)\n",
    "print('Max Sequence length for inputs:',max_encoder_seq_len)\n",
    "print('Max Sequence length for outputs:',max_decoder_seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining token2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token2index=dict([(word,i) for i,word in enumerate(input_tokens)])\n",
    "output_token2index=dict([(word,i) for i,word in enumerate(output_tokens)])\n",
    "output_index2token=dict([(i,word) for i,word in enumerate(output_tokens)])\n",
    "input_token2index['UNK']=num_encoder_tokens-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0', 1: '1'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_index2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defing encoder_input,decoder_input and decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data=np.zeros((len(input_resumes),max_encoder_seq_len,num_encoder_tokens),dtype='float32')\n",
    "decoder_target_data=np.zeros((len(input_resumes),num_decoder_tokens),dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_resumes,output_summary)):\n",
    "    for t,word in enumerate(input_text.split()[:max_encoder_seq_len]):\n",
    "        if word not in input_token2index:\n",
    "            word=\"UNK\"\n",
    "        encoder_input_data[i,t,input_token2index[word]]=1\n",
    "    decoder_target_data[i,output_token2index[target_text]]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 128)               2114048   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,114,306\n",
      "Trainable params: 2,114,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(latent_dim, return_sequences=False,\n",
    "input_shape=(max_encoder_seq_len,num_encoder_tokens,)))\n",
    "model.add(Dense(num_decoder_tokens))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_data, iteration:3\n",
      "Iteration: 4\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.5835 - acc: 0.7545 - val_loss: 0.4561 - val_acc: 0.8167\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.4123 - acc: 0.8152 - val_loss: 0.4020 - val_acc: 0.9024\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.2601 - acc: 0.8914 - val_loss: 0.3077 - val_acc: 0.8964\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.2195 - acc: 0.9148 - val_loss: 0.3227 - val_acc: 0.9004\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.1521 - acc: 0.9437 - val_loss: 0.3376 - val_acc: 0.8805\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 53s 27ms/step - loss: 0.1417 - acc: 0.9512 - val_loss: 0.4543 - val_acc: 0.7629\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.1137 - acc: 0.9597 - val_loss: 0.4091 - val_acc: 0.8845\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 47s 24ms/step - loss: 0.0839 - acc: 0.9701 - val_loss: 0.4984 - val_acc: 0.8825\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0839 - acc: 0.9706 - val_loss: 0.5631 - val_acc: 0.8665\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0720 - acc: 0.9741 - val_loss: 0.6515 - val_acc: 0.8745\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0702 - acc: 0.9756 - val_loss: 0.5896 - val_acc: 0.8546\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0488 - acc: 0.9841 - val_loss: 0.7719 - val_acc: 0.8625\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0737 - acc: 0.9746 - val_loss: 0.3885 - val_acc: 0.8586\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0461 - acc: 0.9836 - val_loss: 0.6591 - val_acc: 0.8546\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0451 - acc: 0.9841 - val_loss: 0.6345 - val_acc: 0.8665\n",
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0542 - acc: 0.9826 - val_loss: 0.7322 - val_acc: 0.8227\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0429 - acc: 0.9866 - val_loss: 0.5830 - val_acc: 0.8566\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 49s 24ms/step - loss: 0.0475 - acc: 0.9836 - val_loss: 0.7814 - val_acc: 0.8347\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0395 - acc: 0.9841 - val_loss: 0.6669 - val_acc: 0.8645\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0495 - acc: 0.9866 - val_loss: 0.6795 - val_acc: 0.8406\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "16/1 roy lane, krishnagar, mobile : 08124454771\n",
      "nadia, wb-741101 aniket dutta email : nktdtt8@gmail.com\n",
      "summary\n",
      " java developer with 3+ years experience in big data technologies and graph databases\n",
      " member of core product development team of allsight and connectid product of\n",
      "infotrellis.\n",
      " experience in building a product from scratch.\n",
      "languages, technologies and tools\n",
      " java, junit, ant, mockito, jconsole\n",
      " hbase, map reduce, titan, tinkerpop\n",
      " elasticsearch, lucene, mapdb, apache jena\n",
      " apache opennlp, cloudera cdh 5.1, weka\n",
      " oozie, hive, pig\n",
      "professional experience\n",
      " senior software engineer at infotrellis india pvt. ltd. chennai\n",
      "role: java developer\n",
      "project description: extracting food mentions from social media data of matched\n",
      "customer data.\n",
      ".\n",
      "responsibilities:\n",
      " understanding the requirements as per client specifications.\n",
      " design and dividing the task into smaller pieces\n",
      " design walk through\n",
      "technologies: google freebase, java, mapdb, apache jena\n",
      "role: java developer\n",
      "mailto:arunkindra@gmail.com\n",
      "project description: sentiment analysis of client specific products in social media using\n",
      "machine learning.\n",
      ".\n",
      "responsibilities:\n",
      " responsible for designing the feature\n",
      " analyzed the patterns in social media, to build training dataset\n",
      " writing code and unit testing\n",
      " integrating and testing the feature with the product.\n",
      "technologies: weka, java, sentiwordnet\n",
      "role: java developer\n",
      "project description: extracting user profession from social media of matched customer\n",
      "data.\n",
      "responsibilities:\n",
      " responsible for designing the feature\n",
      " building profession hierarchy graph from freebase.\n",
      " code and unit testing\n",
      " integration with the product\n",
      "technologies: google freebase, java, tinker graph\n",
      "role: java developer\n",
      "project description: matching engine social user to customer data\n",
      "responsibilities:\n",
      " responsible for coding and unit testing the various matching strategies\n",
      " suggesting algorithms for the different matching scenarios.\n",
      " participated in the analysis of matched customer data.\n",
      "\n",
      "---OUTPUT-----\n",
      "summary\n",
      " java developer with 3+ years experience in big data technologies and graph databases\n",
      " member of core product development team of allsight and connectid product of\n",
      "infotrellis.\n",
      " experience in building a product from scratch.\n",
      " code and unit testing\n",
      "\n",
      "                                                  --------------------------------------------------\n",
      "Iteration: 5\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 56s 28ms/step - loss: 0.0360 - acc: 0.9885 - val_loss: 0.7456 - val_acc: 0.8446\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0398 - acc: 0.9846 - val_loss: 0.7611 - val_acc: 0.8406\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0414 - acc: 0.9871 - val_loss: 0.7538 - val_acc: 0.8267\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0366 - acc: 0.9905 - val_loss: 0.8663 - val_acc: 0.8088\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0300 - acc: 0.9900 - val_loss: 0.6740 - val_acc: 0.8347\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0370 - acc: 0.9880 - val_loss: 0.7180 - val_acc: 0.7928\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0342 - acc: 0.9875 - val_loss: 0.7996 - val_acc: 0.8287\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 47s 24ms/step - loss: 0.0327 - acc: 0.9890 - val_loss: 0.5824 - val_acc: 0.7988\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0360 - acc: 0.9885 - val_loss: 0.6931 - val_acc: 0.8566\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0325 - acc: 0.9880 - val_loss: 0.8093 - val_acc: 0.8088\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 53s 26ms/step - loss: 0.0314 - acc: 0.9905 - val_loss: 0.9782 - val_acc: 0.8406\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 51s 26ms/step - loss: 0.0260 - acc: 0.9905 - val_loss: 0.8988 - val_acc: 0.8088\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 57s 29ms/step - loss: 0.0308 - acc: 0.9915 - val_loss: 0.8088 - val_acc: 0.8127\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0300 - acc: 0.9900 - val_loss: 1.0788 - val_acc: 0.8048\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0254 - acc: 0.9925 - val_loss: 1.4219 - val_acc: 0.8108\n",
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0318 - acc: 0.9895 - val_loss: 0.6066 - val_acc: 0.8227\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0288 - acc: 0.9915 - val_loss: 1.1675 - val_acc: 0.8207\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 49s 24ms/step - loss: 0.0329 - acc: 0.9880 - val_loss: 1.1252 - val_acc: 0.8287\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0295 - acc: 0.9910 - val_loss: 1.0153 - val_acc: 0.7988\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 49s 25ms/step - loss: 0.0254 - acc: 0.9915 - val_loss: 1.1693 - val_acc: 0.8108\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "ccip\n",
      "ccie ( r&s written )\n",
      "work\n",
      "experience\n",
      "cisco systems april 2010 — december 2014\n",
      "cisco network engineer , technical services\n",
      "experience summary :\n",
      "i started my career with cisco systems as a lan-switching network engineer (tac) in\n",
      "rtp timezone and later shifted to asia-pacific timezone as a routing protocols engineer\n",
      "and currently working with dimension data and have an experience of 5 years and 3\n",
      "months in routing and switching and 6 months in security domain.\n",
      "i am skilled in analyzing information system needs, evaluating end-user requirements\n",
      "and troubleshooting complex enterprise level networks.\n",
      "scope 1: network engineer (tac) in routing protocols team :\n",
      "responsibilities :\n",
      "work under extremely high pressure for network down situations for worldwide\n",
      "cisco customers including isps and banks.\n",
      "troubleshooting routing related issues. for example : routing loops , routes\n",
      "missing , route flaps and layer 3 reachability issues.\n",
      "lab recreates for customer network issues using ixia , wireshark and other\n",
      "available tools.\n",
      "troubleshooting production networks in business hours without impacting the\n",
      "working traffic.\n",
      "have been part of several initiatives to optimize the processes and increase\n",
      "productivity.\n",
      "part of various collaborations between tac and business units, advanced services\n",
      "and other organizational units to enhance customer experience for cisco\n",
      "products.\n",
      "being passionate about technical content creation and knowledge reuse, have\n",
      "created many documents for tac troubleshooting , both in routing and switching.\n",
      "core hands on experience in working with cisco router/switches in scalable\n",
      "environment.\n",
      "amit singh\n",
      "amit sing h 1\n",
      "resume_aishwaryadurai\n",
      "mailto : aishu.eashwar@gmail.com\n",
      "phone: +91 9916425500\n",
      "aishwarya durai\n",
      "phone : +91 9916425500\n",
      "mailto : aishu.eashwar@gmail.com\n",
      "______________________________________________________________________________________________\n",
      "experience summary\n",
      " having total experience of 5 years in analysis, design, development and defect fixing of atg\n",
      "framework - java based e-commerce applications\n",
      " earned the credential oracle atg web commerce suite 10 implementation developer certified\n",
      "implementation specialist and is recognized by oracle university as a certified specialist\n",
      " currently working as a senior developer in professional access software development pvt. ltd.\n",
      " have worked in technology excellence group's retail multi-channel practice as a developer in tata\n",
      "consultancy services, chennai\n",
      " gained expertise in atg framework, java/j2ee and restful webservices.\n",
      "\n",
      "---OUTPUT-----\n",
      "experience summary\n",
      " having total experience of 5 years in analysis, design, development and defect fixing of atg\n",
      "framework - java based e-commerce applications\n",
      " earned the credential oracle atg web commerce suite 10 implementation developer certified\n",
      "implementation specialist and is recognized by oracle university as a certified specialist\n",
      " currently working as a senior developer in professional access software development pvt. ltd.\n",
      " have worked in technology excellence group's retail multi-channel practice as a developer in tata\n",
      "consultancy services, chennai\n",
      " gained expertise in atg framework, java/j2ee and restful webservices.\n",
      "\n",
      "                                                  --------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.7324 - val_acc: 0.8426\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0297 - acc: 0.9895 - val_loss: 1.0198 - val_acc: 0.8347\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0298 - acc: 0.9885 - val_loss: 1.2313 - val_acc: 0.8167\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0285 - acc: 0.9920 - val_loss: 0.9279 - val_acc: 0.8207\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0271 - acc: 0.9910 - val_loss: 0.9621 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0295 - acc: 0.9925 - val_loss: 0.6974 - val_acc: 0.8048\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0277 - acc: 0.9890 - val_loss: 0.6671 - val_acc: 0.8167\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0287 - acc: 0.9890 - val_loss: 0.8861 - val_acc: 0.7988\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 51s 25ms/step - loss: 0.0294 - acc: 0.9910 - val_loss: 1.1717 - val_acc: 0.8247\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 47s 24ms/step - loss: 0.0267 - acc: 0.9905 - val_loss: 1.5298 - val_acc: 0.8088\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0307 - acc: 0.9885 - val_loss: 0.9233 - val_acc: 0.7908\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0253 - acc: 0.9915 - val_loss: 1.0621 - val_acc: 0.7669\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0307 - acc: 0.9885 - val_loss: 0.9078 - val_acc: 0.8327\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 47s 24ms/step - loss: 0.0246 - acc: 0.9915 - val_loss: 0.6652 - val_acc: 0.8247\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0256 - acc: 0.9925 - val_loss: 1.4360 - val_acc: 0.8287\n",
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 45s 22ms/step - loss: 0.0314 - acc: 0.9885 - val_loss: 1.1304 - val_acc: 0.8108\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0280 - acc: 0.9920 - val_loss: 0.9148 - val_acc: 0.8386\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0249 - acc: 0.9920 - val_loss: 1.0967 - val_acc: 0.8247\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0241 - acc: 0.9915 - val_loss: 1.3266 - val_acc: 0.8267\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0264 - acc: 0.9920 - val_loss: 1.3139 - val_acc: 0.8307\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "applications. presently working as a senior development manager with oracle india pvt\n",
      "ltd., noida. a self motivated seasoned problem-solver, coder and a manager who gives\n",
      "technical direction to the team with proven success in building and integrating stellar\n",
      "development teams and delivering innovative enterprise software solutions. articulates a\n",
      "vision to drive the business and the product teams to realize the opportunities.\n",
      "expertise in high and low level designing, coding (ui and backend), product vision, code\n",
      "reviews, debugging, handling critical customer issues, managing quality on time deliveries,\n",
      "across geography team management, problem solving, interviewing, employee retention,\n",
      "working in a startup like environment.\n",
      "objective\n",
      "being a part of a team/organization that believes in customer/market centric delivery with\n",
      "quality, has cordial and converging work atmosphere giving a chance to learn new things\n",
      "every day that would help me boost my professional career and technical expertise and\n",
      "shape me as a better leader, a better engineer and also a better human being\n",
      "educational qualification\n",
      "qualification institute marks year\n",
      "b.e. in computer science\n",
      "punjab engineering college,\n",
      "chandigarh\n",
      "73.8%\n",
      "2004\n",
      "class 12th (c.b.s.e) d.a.v. college, chandigarh 83.2% 2000\n",
      "class 10th (i.c.s.e) st. edward’s school, shimla 93.2% 1998\n",
      "employment history\n",
      "company period designation work area/responsibilities\n",
      "oracle india private\n",
      "limited, noida\n",
      "may-2008 to present senior software\n",
      "development\n",
      "manager\n",
      "design, coding, managing\n",
      "distributed teams, agile, scrum,\n",
      "code reviews, hiring, customer\n",
      "issues, managing multiple\n",
      "products’ development and\n",
      "releases, high availability, load\n",
      "balancing, web services, rest\n",
      "apis, scripting, ui\n",
      "development,\n",
      "public/private/hybrid cloud\n",
      "mailto:avaidya3008@gmail.com\n",
      "adobe systems,\n",
      "noida\n",
      "microsoft word - anil_prabhu_resume.rtf\n",
      "address: #109/19/2 ‘hira sadan’,\n",
      "7th cross lower palace orchards,\n",
      "bangalore -560003.\n",
      "email:anilprabhu1988@gmail.com\n",
      "mobile: +91-9886594775\n",
      "anil prabhu\n",
      "\n",
      "---OUTPUT-----\n",
      "applications. presently working as a senior development manager with oracle india pvt\n",
      "ltd., noida. a self motivated seasoned problem-solver, coder and a manager who gives\n",
      "technical direction to the team with proven success in building and integrating stellar\n",
      "development teams and delivering innovative enterprise software solutions. articulates a\n",
      "vision to drive the business and the product teams to realize the opportunities.\n",
      "expertise in high and low level designing, coding (ui and backend), product vision, code\n",
      "reviews, debugging, handling critical customer issues, managing quality on time deliveries,\n",
      "across geography team management, problem solving, interviewing, employee retention,\n",
      "working in a startup like environment.\n",
      "objective\n",
      "being a part of a team/organization that believes in customer/market centric delivery with\n",
      "quality, has cordial and converging work atmosphere giving a chance to learn new things\n",
      "every day that would help me boost my professional career and technical expertise and\n",
      "shape me as a better leader, a better engineer and also a better human being\n",
      "\n",
      "                                                  --------------------------------------------------\n",
      "Iteration: 7\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0305 - acc: 0.9900 - val_loss: 1.1217 - val_acc: 0.8108\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0338 - acc: 0.9895 - val_loss: 0.9931 - val_acc: 0.8267\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0226 - acc: 0.9895 - val_loss: 1.1249 - val_acc: 0.8367\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 45s 22ms/step - loss: 0.0234 - acc: 0.9905 - val_loss: 1.2435 - val_acc: 0.8187\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0278 - acc: 0.9890 - val_loss: 0.9596 - val_acc: 0.8227\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0294 - acc: 0.9905 - val_loss: 0.9903 - val_acc: 0.8127\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 49s 24ms/step - loss: 0.0212 - acc: 0.9915 - val_loss: 1.1441 - val_acc: 0.8008\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 54s 27ms/step - loss: 0.0246 - acc: 0.9925 - val_loss: 1.0075 - val_acc: 0.8127\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 53s 27ms/step - loss: 0.0254 - acc: 0.9885 - val_loss: 1.1321 - val_acc: 0.8167\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 51s 25ms/step - loss: 0.0217 - acc: 0.9920 - val_loss: 1.3395 - val_acc: 0.8127\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0264 - acc: 0.9930 - val_loss: 1.0599 - val_acc: 0.8227\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0244 - acc: 0.9925 - val_loss: 1.1747 - val_acc: 0.8167\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0230 - acc: 0.9905 - val_loss: 1.1194 - val_acc: 0.8048\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0219 - acc: 0.9900 - val_loss: 1.5622 - val_acc: 0.8088\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0214 - acc: 0.9920 - val_loss: 1.7705 - val_acc: 0.8028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0261 - acc: 0.9910 - val_loss: 1.1058 - val_acc: 0.8207\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0207 - acc: 0.9920 - val_loss: 1.2589 - val_acc: 0.8227\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0225 - acc: 0.9920 - val_loss: 1.1124 - val_acc: 0.8307\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0221 - acc: 0.9925 - val_loss: 1.2314 - val_acc: 0.8267\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0468 - acc: 0.9900 - val_loss: 1.1764 - val_acc: 0.8147\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      " carrying 3.10 years of qualitative experience in software testing with key strengths in web/mobile\n",
      "application testing (android, ios, blackberry and windows).\n",
      " presently associated with tata consultancy services, chennai as systems engineer.\n",
      " exposure on both manual/automation testing.\n",
      " knowledge in selenium ide, web driver and appium.\n",
      " experience in different software testing techniques end-to-end, functional, system, regression, acceptance\n",
      "and performance testing.\n",
      " have sound knowledge in core java and javascript.\n",
      " exposure to agile methodologies and participated in daily scrum meetings, retrospective meetings\n",
      "and sprint planning.\n",
      " good understanding of test process and all phases of software development lifecycle and software\n",
      "testing lifecycle.\n",
      " effectively involved in developing test plan, test scenarios, test cases, test procedures, bug tracking,\n",
      "reporting reviewing and analyzing test results.\n",
      " exposure on defect management tools hp quality center and jira.\n",
      " working experience in domains: banking, retail, insurance and tourism\n",
      " have received personal appreciations from the scrum master for my good work and for going beyond my\n",
      "call of work to get things done.\n",
      " quick learner with the ability to grasp new technologies.\n",
      " always look forward with ideas exhibiting a “can do” attitude.\n",
      " keen that “quality ” of the product delivered is not negotiated, in the process of meeting the strict timelines.\n",
      " team player with effective communication skills and proven abilities in resolving issues.\n",
      "technical skills\n",
      "automation tools : selenium ide, web driver, appium, perfecto mobile\n",
      "programming languages : c, core java, java script\n",
      "defect management tools : hp quality center, jira\n",
      "other tools : svn, jenkins\n",
      "certifications:\n",
      " istqb certification of software testing-foundation level\n",
      "indian testing b\n",
      "professional experience\n",
      "project#1:\n",
      "client : royal bank of scotland\n",
      "role : test engineer\n",
      "description:\n",
      "royal bank of scotland is an international banking and financial services company. with emerging digital\n",
      "technology,rbs mobile banking app,enables customer in managing money on the move, easy,fast and secure.\n",
      "application is available on android, ios, blackberry and windows. app has host of cutting edge features such as\n",
      "getcash, pay your contacts which has enabled the customers to manage their money at ease. recently rbs has\n",
      "delivered app with fingerprint technology and it is the first uk bank to use apple’s touch-id fingerprint sensor to\n",
      "verify users.\n",
      "responsibilities:\n",
      " leading the ios team and sme for rbs ios application\n",
      " key member in delivering zero defect rbs mobile app with fingerprint technology and had received personal\n",
      "appreciation from the scrum master for the same.\n",
      "resume\n",
      "abhilash purohit abhipurohit111@gmail.com\n",
      "+91-9916731772\n",
      "executive summary\n",
      " b.tech in information technology with 3.8 years of programming experience as an oracle\n",
      "\n",
      "---OUTPUT-----\n",
      " carrying 3.10 years of qualitative experience in software testing with key strengths in web/mobile\n",
      "application testing (android, ios, blackberry and windows).\n",
      " presently associated with tata consultancy services, chennai as systems engineer.\n",
      " exposure on both manual/automation testing.\n",
      " knowledge in selenium ide, web driver and appium.\n",
      " experience in different software testing techniques end-to-end, functional, system, regression, acceptance\n",
      "and performance testing.\n",
      " have sound knowledge in core java and javascript.\n",
      " exposure to agile methodologies and participated in daily scrum meetings, retrospective meetings\n",
      "and sprint planning.\n",
      " good understanding of test process and all phases of software development lifecycle and software\n",
      "testing lifecycle.\n",
      " effectively involved in developing test plan, test scenarios, test cases, test procedures, bug tracking,\n",
      "reporting reviewing and analyzing test results.\n",
      " exposure on defect management tools hp quality center and jira.\n",
      " working experience in domains: banking, retail, insurance and tourism\n",
      " have received personal appreciations from the scrum master for my good work and for going beyond my\n",
      "call of work to get things done.\n",
      " quick learner with the ability to grasp new technologies.\n",
      " always look forward with ideas exhibiting a “can do” attitude.\n",
      " keen that “quality ” of the product delivered is not negotiated, in the process of meeting the strict timelines.\n",
      " team player with effective communication skills and proven abilities in resolving issues.\n",
      "executive summary\n",
      " b.tech in information technology with 3.8 years of programming experience as an oracle\n",
      "\n",
      "                                                  --------------------------------------------------\n",
      "Iteration: 8\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0200 - acc: 0.9910 - val_loss: 1.3913 - val_acc: 0.8167\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 39s 20ms/step - loss: 0.0222 - acc: 0.9925 - val_loss: 1.1724 - val_acc: 0.8227\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 34s 17ms/step - loss: 0.0217 - acc: 0.9915 - val_loss: 1.2898 - val_acc: 0.8187\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 36s 18ms/step - loss: 0.0213 - acc: 0.9905 - val_loss: 1.3630 - val_acc: 0.8386\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 38s 19ms/step - loss: 0.0301 - acc: 0.9910 - val_loss: 0.9049 - val_acc: 0.8367\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 36s 18ms/step - loss: 0.0219 - acc: 0.9915 - val_loss: 1.0316 - val_acc: 0.8247\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 35s 18ms/step - loss: 0.0207 - acc: 0.9905 - val_loss: 1.0886 - val_acc: 0.8347\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 35s 17ms/step - loss: 0.0221 - acc: 0.9925 - val_loss: 1.1048 - val_acc: 0.8327\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 33s 17ms/step - loss: 0.0229 - acc: 0.9920 - val_loss: 1.1325 - val_acc: 0.8406\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 34s 17ms/step - loss: 0.0234 - acc: 0.9925 - val_loss: 1.2506 - val_acc: 0.8307\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0690 - acc: 0.9866 - val_loss: 1.0206 - val_acc: 0.8307\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 33s 16ms/step - loss: 0.0212 - acc: 0.9930 - val_loss: 1.1183 - val_acc: 0.8267\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0242 - acc: 0.9930 - val_loss: 0.9871 - val_acc: 0.8267\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0206 - acc: 0.9910 - val_loss: 1.0108 - val_acc: 0.8287\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 34s 17ms/step - loss: 0.0238 - acc: 0.9930 - val_loss: 0.9763 - val_acc: 0.8347\n",
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 37s 18ms/step - loss: 0.0303 - acc: 0.9915 - val_loss: 1.0668 - val_acc: 0.8187\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 38s 19ms/step - loss: 0.0218 - acc: 0.9915 - val_loss: 1.1551 - val_acc: 0.8267\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 35s 17ms/step - loss: 0.0228 - acc: 0.9930 - val_loss: 0.8958 - val_acc: 0.8386\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0205 - acc: 0.9930 - val_loss: 1.2208 - val_acc: 0.8327\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 33s 16ms/step - loss: 0.0216 - acc: 0.9935 - val_loss: 1.1530 - val_acc: 0.8187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "publication:\n",
      "book name\n",
      "e-governance in india - priorities, challenges & benefits” published by lambert academic\n",
      "publishing gmbh & co. in october 12, 2011\n",
      "summary\n",
      "my publication is review of current trends and strategies in the area of e-governance. in the current\n",
      "democracies, there is an increasing demand to bring citizens closer to the government and to improve\n",
      "delivery of government services.\n",
      "professional awards:\n",
      "star awards\n",
      " recognized as an individual contributor for outstanding quarterly technical excellence contributing to\n",
      "a research & innovation of new product, cross-group technology transfer, mentorship “above and\n",
      "b\n",
      "b.aravindhan\n",
      "email: b.aravind87@gmail.com\n",
      "mobile: +91 7406006123\n",
      "career objective:\n",
      "seeking a excellent and challenging career in an information and communication technology organization\n",
      "where i can show my leadership and teamwork skills that would mold me into a dynamic leader both in my approach and\n",
      "attitude thus resulting in the mutual development of both the organization and me.\n",
      "professional experience:\n",
      "having a work experience of about 6 years in ict (information & communication technology) industry on multi-\n",
      "vendor mobile packet core, policy and charging products, project-management, team-management and quality management.\n",
      "handled service delivery of multiple customer engagements.\n",
      "designation organization from to\n",
      "software change management\n",
      "engineer (mobile packet core)\n",
      "nokia siemens networks india. pvt. ltd\n",
      "feb-2010 aug-2012\n",
      "engineer -2nd level assurance (ps\n",
      "core & ip networks)\n",
      "ericsson india global services pvt. ltd sep-2012 oct-2013\n",
      "subject matter expert - (tac)\n",
      "technical assistance center\n",
      "cisco systems india pvt. ltd nov-2013 till date\n",
      "key accomplishments:\n",
      " awarded as a process champion by nokia siemens networks (nsn) for the implementation of best\n",
      "practices and process in the vodafone-india service account across 12 managed services circle (team size of\n",
      "approximately 4000)\n",
      " knowledge champions league (kcl) winner in cisco for consecutive two years (fy14 & fy15) across\n",
      "technical services organization among 8000 tac engineers for creating a quality documents and proactive\n",
      "customer approach as a part of intellectual capital reuse (iccr) business initiative\n",
      " c-lead award for learning and collaboration by cisco for quick ramp up on new technology and\n",
      "outstanding support for k-opticom japan project.\n",
      " brand ambassador for nokia siemens networks in tamil nadu circle,(sep-2010 –jan-2012) promoting\n",
      "the nsn values and technology advancements and mobile communication evolution to educational\n",
      "institutions(visited three technical institutions which includes psg velammal and mepco schelenk\n",
      "engineering college)\n",
      "professional certifications:\n",
      " red-hat certified engineer (rhce) and system administrator (rhcsa)\n",
      "\n",
      "---OUTPUT-----\n",
      "summary\n",
      "career objective:\n",
      "seeking a excellent and challenging career in an information and communication technology organization\n",
      "where i can show my leadership and teamwork skills that would mold me into a dynamic leader both in my approach and\n",
      "attitude thus resulting in the mutual development of both the organization and me.\n",
      "professional experience:\n",
      "having a work experience of about 6 years in ict (information & communication technology) industry on multi-\n",
      "vendor mobile packet core, policy and charging products, project-management, team-management and quality management.\n",
      "handled service delivery of multiple customer engagements.\n",
      "designation organization from to\n",
      "software change management\n",
      "engineer (mobile packet core)\n",
      "nokia siemens networks india. pvt. ltd\n",
      "feb-2010 aug-2012\n",
      "engineer -2nd level assurance (ps\n",
      "core & ip networks)\n",
      "ericsson india global services pvt. ltd sep-2012 oct-2013\n",
      "subject matter expert - (tac)\n",
      "technical assistance center\n",
      "cisco systems india pvt. ltd nov-2013 till date\n",
      "professional certifications:\n",
      "\n",
      "                                                  --------------------------------------------------\n",
      "Iteration: 9\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 34s 17ms/step - loss: 0.0259 - acc: 0.9920 - val_loss: 0.8783 - val_acc: 0.8367\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 34s 17ms/step - loss: 0.0214 - acc: 0.9915 - val_loss: 1.3079 - val_acc: 0.8367\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 34s 17ms/step - loss: 0.0242 - acc: 0.9910 - val_loss: 0.9770 - val_acc: 0.8426\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 35s 17ms/step - loss: 0.0305 - acc: 0.9900 - val_loss: 1.1033 - val_acc: 0.8187\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0183 - acc: 0.9935 - val_loss: 1.1527 - val_acc: 0.8386\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0237 - acc: 0.9935 - val_loss: 1.2847 - val_acc: 0.7888\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0301 - acc: 0.9915 - val_loss: 1.1136 - val_acc: 0.8367\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0177 - acc: 0.9925 - val_loss: 1.3238 - val_acc: 0.8347\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0192 - acc: 0.9935 - val_loss: 0.9646 - val_acc: 0.8267\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0203 - acc: 0.9935 - val_loss: 1.1865 - val_acc: 0.8406\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0235 - acc: 0.9920 - val_loss: 1.1942 - val_acc: 0.8307\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0429 - acc: 0.9895 - val_loss: 1.1480 - val_acc: 0.8167\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 33s 16ms/step - loss: 0.0186 - acc: 0.9915 - val_loss: 1.2753 - val_acc: 0.8307\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0332 - acc: 0.9885 - val_loss: 1.1599 - val_acc: 0.8307\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 34s 17ms/step - loss: 0.0196 - acc: 0.9930 - val_loss: 1.2402 - val_acc: 0.8187\n",
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0181 - acc: 0.9930 - val_loss: 1.2988 - val_acc: 0.8367\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 33s 16ms/step - loss: 0.0201 - acc: 0.9935 - val_loss: 1.3273 - val_acc: 0.8267\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0213 - acc: 0.9930 - val_loss: 1.0653 - val_acc: 0.8167\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0212 - acc: 0.9925 - val_loss: 1.2489 - val_acc: 0.8187\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 32s 16ms/step - loss: 0.0214 - acc: 0.9925 - val_loss: 1.0710 - val_acc: 0.8386\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "test cases and peer reviews. worked with different teams & different work environment:\n",
      " created js validator by using esprima ,node js and configured with git and jenkins with team size of 2\n",
      " episode modules with team size of 6 and 13.\n",
      "o creating views using dtml.\n",
      "o managing controller and model using python.\n",
      "o queries in mssql and oracle.\n",
      "o handling ui using native js and yui.\n",
      "sumeet gupta\n",
      "amit vishal mundu\n",
      "8928250322\n",
      "amit.v.mundu@gmail.com\n",
      "objective:\n",
      "to work in a reputed organization where innovation, dynamism & talent in an individual is\n",
      "appreciated and ample opportunity is provided so that one can perform well and grow with the\n",
      "organization.\n",
      "education:\n",
      "2006–2010\n",
      "national institute of technology, rourkela\n",
      "computer science & engg., bachelor of technology - 8.3cgpa\n",
      "2006 - 12th\n",
      "kendriya vidyalaya sundargarh, odisha - 85.8%\n",
      "cbse board\n",
      "2004 - 10th\n",
      "kendriya vidyalaya sundargarh, odisha - 85.8%\n",
      "cbse board\n",
      "work experience:\n",
      "pso software engineer ii (professional services) november 2012 -present\n",
      "egain communications , pune, india\n",
      " worked on multiple issues for multiple customers, debugging on java, javascript, sql and\n",
      "did a lot of performance analysis as well.\n",
      " currently leading a team of 3 to develop self-service portal, for helping their customers to\n",
      "prepare one stage where customers can serve their queries with ease.\n",
      " integral part of the team who developed the ocr functionality for mail system which\n",
      "will fetch pdf files from ftp and make a mail out of it.\n",
      " developed secure mobile ui using primefaces(jsf framework), for a large consumer\n",
      "company. integrated saml for single sign on for the same.\n",
      " developed a restful web service using jersey, integrating customer facing knowledge\n",
      "management system with egain knowledge base.\n",
      "associate systems engineer, ibm india pvt ltd, pune july 2010 – october 2012 (2 years)\n",
      "project title: monti pachi the siena (mps)\n",
      "client : monti pachi the siena (italian bank).\n",
      "duration : july 2010 – october 2012\n",
      "technology : java, servlet , jsp, junit 4, icefaces.\n",
      "server : jboss community 5.1, tomcat 6.0\n",
      "database : db2\n",
      "role : java developer\n",
      "project description: mps is the 3\n",
      "rd\n",
      "largest italian bank in italy whose current system is based\n",
      "on mainframes and wants to upgrade to webservices.the team consists of almost 120 members\n",
      "\n",
      "---OUTPUT-----\n",
      "objective:\n",
      "to work in a reputed organization where innovation, dynamism & talent in an individual is\n",
      "appreciated and ample opportunity is provided so that one can perform well and grow with the\n",
      "organization.\n",
      "\n",
      "                                                  --------------------------------------------------\n",
      "Iteration: 10\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008/2008 [==============================] - 35s 17ms/step - loss: 0.0199 - acc: 0.9925 - val_loss: 1.4571 - val_acc: 0.8247\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-feb30e924409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m           validation_split=0.2,callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#prepare sample_data to test 5 samples:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "iteration=0\n",
    "\"\"\"\n",
    "# load weights\n",
    "print('loading the weights')\n",
    "model=load_model('resume_level.h5')\n",
    "\n",
    "# estimate accuracy on whole dataset using loaded weights\n",
    "scores = model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data,verbose=0)\n",
    "print(\"%s: %.2f%%\\n\\n\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"Testing Samples\\n\"+\"-\"*50)\n",
    "for i in range(1):\n",
    "    index=np.random.randint(len(input_resumes))\n",
    "    encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "    output_sequence=decode_sequence(encoded_input_sequence)\n",
    "    print(\"-\"*50)\n",
    "    print(input_resumes[index])\n",
    "    print(\" \"*50)\n",
    "    print(\"*\"*50+\"\\nOUTPUT\"+\" \"*50)\n",
    "    print(output_sequence)\n",
    "    print(\"-\"*50+\"\\n\"+\" \"*50)\n",
    "\"\"\"\n",
    "iteration_file=\"/home/santhosh/resumes_folder/keras/extract_summary_and_objective/iteration_resume_line_classification.txt\"\n",
    "try:\n",
    "    file=open(iteration_file,'r')\n",
    "    last_line=file.read().split('\\n')[-2]\n",
    "    print('file_data,',last_line)\n",
    "    iteration=int(last_line.split(':')[1])\n",
    "    #print(iteration)\n",
    "    file.close()\n",
    "    \n",
    "except:\n",
    "    print('no file exist')\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"resume_line_classification_checkpoints.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "while True:\n",
    "    print('Iteration:',iteration+1)\n",
    "    #training\n",
    "    model.fit(encoder_input_data,decoder_target_data ,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,callbacks=callbacks_list)\n",
    "    \n",
    "    #prepare sample_data to test 5 samples:\n",
    "    print(\"-\"*50)\n",
    "    index=int(np.random.randint(len(input_resumes)/40*0.8)*40)\n",
    "    test_input=\"\"\n",
    "    test_output=\"\"\n",
    "    for i in range(50):\n",
    "        \n",
    "        encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "        output_sequence=model.predict(encoded_input_sequence, verbose=0)[0]\n",
    "        output_sequence = output_index2token[np.argmax(output_sequence)]\n",
    "        test_input+=input_resumes[index]+'\\n'\n",
    "        if output_sequence==\"1\":\n",
    "            output_sequence=input_resumes[index]+'\\n'\n",
    "        else:\n",
    "            output_sequence=''\n",
    "        test_output+=output_sequence\n",
    "        index+=1\n",
    "    print(\"-\"*50)\n",
    "    print(test_input)\n",
    "    print(\"---OUTPUT-----\")\n",
    "    print(test_output)\n",
    "    print(\" \"*50+\"-\"*50)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Save model\n",
    "    file=open(iteration_file,'a')\n",
    "    file.write('iteration:'+str(iteration+1)+'\\n')\n",
    "    file.close()\n",
    "    iteration+=1\n",
    "    model.save('resume_line_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
