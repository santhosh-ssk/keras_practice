{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence model to extract summary,objective from resume (input: resume line by line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 207 resumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import csv,os\n",
    "import collections\n",
    "from keras.models import load_model,Sequential\n",
    "from keras.layers import Input,LSTM,Dense,Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "batch_size=128\n",
    "epochs=20\n",
    "latent_dim=128\n",
    "data_path=\"/home/santhosh/resumes_folder/custom_annotator/annotator-server/static/files/Data_Tracter_Resumes_in_TXT/csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resumes=[]\n",
    "output_summary=[]\n",
    "input_tokens=collections.Counter()\n",
    "output_tokens=set()\n",
    "files=os.listdir(data_path)\n",
    "count=0\n",
    "for file in files[:50]:\n",
    "    with open(data_path+'/'+file,'r') as csv_file:\n",
    "        reader=csv.reader(csv_file)\n",
    "        count=0\n",
    "        for Input_text,output_text in reader:\n",
    "            Input_text=Input_text.strip().lower()\n",
    "            Input_text=Input_text\n",
    "            \n",
    "            input_resumes.append(Input_text)\n",
    "            output_summary.append(output_text)\n",
    "            \n",
    "            for word in Input_text.split():\n",
    "                if word not in input_tokens:\n",
    "                    input_tokens[word]+=1\n",
    "            for word in output_text.split():\n",
    "                if word not in output_tokens:\n",
    "                    output_tokens.add(word)\n",
    "            if count==50:\n",
    "                break\n",
    "            count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5179\n",
      "Number of samples: 2510\n",
      "number of unique input token: 4000\n",
      "number of unique output token: 2\n",
      "Max Sequence length for inputs: 24\n",
      "Max Sequence length for outputs: 1\n"
     ]
    }
   ],
   "source": [
    "print(len(input_tokens))\n",
    "num_encoder_tokens=min(len(input_tokens),4000)\n",
    "input_tokens=[word for word,count in input_tokens.most_common(num_encoder_tokens-1)]\n",
    "input_tokens=sorted(list(input_tokens))\n",
    "output_tokens=sorted(list(output_tokens))\n",
    "num_decoder_tokens=len(output_tokens)\n",
    "max_encoder_seq_len=max([len(text.split()) for text in input_resumes])\n",
    "max_decoder_seq_len=max([len(text.split()) for text in output_summary])\n",
    "\n",
    "print('Number of samples:',len(input_resumes))\n",
    "print('number of unique input token:',num_encoder_tokens)\n",
    "print('number of unique output token:',num_decoder_tokens)\n",
    "print('Max Sequence length for inputs:',max_encoder_seq_len)\n",
    "print('Max Sequence length for outputs:',max_decoder_seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining token2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token2index=dict([(word,i) for i,word in enumerate(input_tokens)])\n",
    "output_token2index=dict([(word,i) for i,word in enumerate(output_tokens)])\n",
    "output_index2token=dict([(i,word) for i,word in enumerate(output_tokens)])\n",
    "input_token2index['UNK']=num_encoder_tokens-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0', 1: '1'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_index2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defing encoder_input,decoder_input and decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data=np.zeros((len(input_resumes),max_encoder_seq_len,num_encoder_tokens),dtype='float32')\n",
    "decoder_target_data=np.zeros((len(input_resumes),num_decoder_tokens),dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_resumes,output_summary)):\n",
    "    for t,word in enumerate(input_text.split()[:max_encoder_seq_len]):\n",
    "        if word not in input_token2index:\n",
    "            word=\"UNK\"\n",
    "        encoder_input_data[i,t,input_token2index[word]]=1\n",
    "    decoder_target_data[i,output_token2index[target_text]]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 128)               2114048   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,114,306\n",
      "Trainable params: 2,114,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(latent_dim, return_sequences=False,\n",
    "input_shape=(max_encoder_seq_len,num_encoder_tokens,)))\n",
    "model.add(Dense(num_decoder_tokens))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_data, iteration:3\n",
      "Iteration: 4\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.5835 - acc: 0.7545 - val_loss: 0.4561 - val_acc: 0.8167\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.4123 - acc: 0.8152 - val_loss: 0.4020 - val_acc: 0.9024\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.2601 - acc: 0.8914 - val_loss: 0.3077 - val_acc: 0.8964\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.2195 - acc: 0.9148 - val_loss: 0.3227 - val_acc: 0.9004\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.1521 - acc: 0.9437 - val_loss: 0.3376 - val_acc: 0.8805\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 53s 27ms/step - loss: 0.1417 - acc: 0.9512 - val_loss: 0.4543 - val_acc: 0.7629\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.1137 - acc: 0.9597 - val_loss: 0.4091 - val_acc: 0.8845\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 47s 24ms/step - loss: 0.0839 - acc: 0.9701 - val_loss: 0.4984 - val_acc: 0.8825\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0839 - acc: 0.9706 - val_loss: 0.5631 - val_acc: 0.8665\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0720 - acc: 0.9741 - val_loss: 0.6515 - val_acc: 0.8745\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0702 - acc: 0.9756 - val_loss: 0.5896 - val_acc: 0.8546\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0488 - acc: 0.9841 - val_loss: 0.7719 - val_acc: 0.8625\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0737 - acc: 0.9746 - val_loss: 0.3885 - val_acc: 0.8586\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0461 - acc: 0.9836 - val_loss: 0.6591 - val_acc: 0.8546\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0451 - acc: 0.9841 - val_loss: 0.6345 - val_acc: 0.8665\n",
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0542 - acc: 0.9826 - val_loss: 0.7322 - val_acc: 0.8227\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0429 - acc: 0.9866 - val_loss: 0.5830 - val_acc: 0.8566\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 49s 24ms/step - loss: 0.0475 - acc: 0.9836 - val_loss: 0.7814 - val_acc: 0.8347\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0395 - acc: 0.9841 - val_loss: 0.6669 - val_acc: 0.8645\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0495 - acc: 0.9866 - val_loss: 0.6795 - val_acc: 0.8406\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "16/1 roy lane, krishnagar, mobile : 08124454771\n",
      "nadia, wb-741101 aniket dutta email : nktdtt8@gmail.com\n",
      "summary\n",
      " java developer with 3+ years experience in big data technologies and graph databases\n",
      " member of core product development team of allsight and connectid product of\n",
      "infotrellis.\n",
      " experience in building a product from scratch.\n",
      "languages, technologies and tools\n",
      " java, junit, ant, mockito, jconsole\n",
      " hbase, map reduce, titan, tinkerpop\n",
      " elasticsearch, lucene, mapdb, apache jena\n",
      " apache opennlp, cloudera cdh 5.1, weka\n",
      " oozie, hive, pig\n",
      "professional experience\n",
      " senior software engineer at infotrellis india pvt. ltd. chennai\n",
      "role: java developer\n",
      "project description: extracting food mentions from social media data of matched\n",
      "customer data.\n",
      ".\n",
      "responsibilities:\n",
      " understanding the requirements as per client specifications.\n",
      " design and dividing the task into smaller pieces\n",
      " design walk through\n",
      "technologies: google freebase, java, mapdb, apache jena\n",
      "role: java developer\n",
      "mailto:arunkindra@gmail.com\n",
      "project description: sentiment analysis of client specific products in social media using\n",
      "machine learning.\n",
      ".\n",
      "responsibilities:\n",
      " responsible for designing the feature\n",
      " analyzed the patterns in social media, to build training dataset\n",
      " writing code and unit testing\n",
      " integrating and testing the feature with the product.\n",
      "technologies: weka, java, sentiwordnet\n",
      "role: java developer\n",
      "project description: extracting user profession from social media of matched customer\n",
      "data.\n",
      "responsibilities:\n",
      " responsible for designing the feature\n",
      " building profession hierarchy graph from freebase.\n",
      " code and unit testing\n",
      " integration with the product\n",
      "technologies: google freebase, java, tinker graph\n",
      "role: java developer\n",
      "project description: matching engine social user to customer data\n",
      "responsibilities:\n",
      " responsible for coding and unit testing the various matching strategies\n",
      " suggesting algorithms for the different matching scenarios.\n",
      " participated in the analysis of matched customer data.\n",
      "\n",
      "---OUTPUT-----\n",
      "summary\n",
      " java developer with 3+ years experience in big data technologies and graph databases\n",
      " member of core product development team of allsight and connectid product of\n",
      "infotrellis.\n",
      " experience in building a product from scratch.\n",
      " code and unit testing\n",
      "\n",
      "                                                  --------------------------------------------------\n",
      "Iteration: 5\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 56s 28ms/step - loss: 0.0360 - acc: 0.9885 - val_loss: 0.7456 - val_acc: 0.8446\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0398 - acc: 0.9846 - val_loss: 0.7611 - val_acc: 0.8406\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0414 - acc: 0.9871 - val_loss: 0.7538 - val_acc: 0.8267\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0366 - acc: 0.9905 - val_loss: 0.8663 - val_acc: 0.8088\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0300 - acc: 0.9900 - val_loss: 0.6740 - val_acc: 0.8347\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0370 - acc: 0.9880 - val_loss: 0.7180 - val_acc: 0.7928\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0342 - acc: 0.9875 - val_loss: 0.7996 - val_acc: 0.8287\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 47s 24ms/step - loss: 0.0327 - acc: 0.9890 - val_loss: 0.5824 - val_acc: 0.7988\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0360 - acc: 0.9885 - val_loss: 0.6931 - val_acc: 0.8566\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0325 - acc: 0.9880 - val_loss: 0.8093 - val_acc: 0.8088\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 53s 26ms/step - loss: 0.0314 - acc: 0.9905 - val_loss: 0.9782 - val_acc: 0.8406\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 51s 26ms/step - loss: 0.0260 - acc: 0.9905 - val_loss: 0.8988 - val_acc: 0.8088\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 57s 29ms/step - loss: 0.0308 - acc: 0.9915 - val_loss: 0.8088 - val_acc: 0.8127\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0300 - acc: 0.9900 - val_loss: 1.0788 - val_acc: 0.8048\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0254 - acc: 0.9925 - val_loss: 1.4219 - val_acc: 0.8108\n",
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0318 - acc: 0.9895 - val_loss: 0.6066 - val_acc: 0.8227\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0288 - acc: 0.9915 - val_loss: 1.1675 - val_acc: 0.8207\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 49s 24ms/step - loss: 0.0329 - acc: 0.9880 - val_loss: 1.1252 - val_acc: 0.8287\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0295 - acc: 0.9910 - val_loss: 1.0153 - val_acc: 0.7988\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 49s 25ms/step - loss: 0.0254 - acc: 0.9915 - val_loss: 1.1693 - val_acc: 0.8108\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "ccip\n",
      "ccie ( r&s written )\n",
      "work\n",
      "experience\n",
      "cisco systems april 2010 — december 2014\n",
      "cisco network engineer , technical services\n",
      "experience summary :\n",
      "i started my career with cisco systems as a lan-switching network engineer (tac) in\n",
      "rtp timezone and later shifted to asia-pacific timezone as a routing protocols engineer\n",
      "and currently working with dimension data and have an experience of 5 years and 3\n",
      "months in routing and switching and 6 months in security domain.\n",
      "i am skilled in analyzing information system needs, evaluating end-user requirements\n",
      "and troubleshooting complex enterprise level networks.\n",
      "scope 1: network engineer (tac) in routing protocols team :\n",
      "responsibilities :\n",
      "work under extremely high pressure for network down situations for worldwide\n",
      "cisco customers including isps and banks.\n",
      "troubleshooting routing related issues. for example : routing loops , routes\n",
      "missing , route flaps and layer 3 reachability issues.\n",
      "lab recreates for customer network issues using ixia , wireshark and other\n",
      "available tools.\n",
      "troubleshooting production networks in business hours without impacting the\n",
      "working traffic.\n",
      "have been part of several initiatives to optimize the processes and increase\n",
      "productivity.\n",
      "part of various collaborations between tac and business units, advanced services\n",
      "and other organizational units to enhance customer experience for cisco\n",
      "products.\n",
      "being passionate about technical content creation and knowledge reuse, have\n",
      "created many documents for tac troubleshooting , both in routing and switching.\n",
      "core hands on experience in working with cisco router/switches in scalable\n",
      "environment.\n",
      "amit singh\n",
      "amit sing h 1\n",
      "resume_aishwaryadurai\n",
      "mailto : aishu.eashwar@gmail.com\n",
      "phone: +91 9916425500\n",
      "aishwarya durai\n",
      "phone : +91 9916425500\n",
      "mailto : aishu.eashwar@gmail.com\n",
      "______________________________________________________________________________________________\n",
      "experience summary\n",
      " having total experience of 5 years in analysis, design, development and defect fixing of atg\n",
      "framework - java based e-commerce applications\n",
      " earned the credential oracle atg web commerce suite 10 implementation developer certified\n",
      "implementation specialist and is recognized by oracle university as a certified specialist\n",
      " currently working as a senior developer in professional access software development pvt. ltd.\n",
      " have worked in technology excellence group's retail multi-channel practice as a developer in tata\n",
      "consultancy services, chennai\n",
      " gained expertise in atg framework, java/j2ee and restful webservices.\n",
      "\n",
      "---OUTPUT-----\n",
      "experience summary\n",
      " having total experience of 5 years in analysis, design, development and defect fixing of atg\n",
      "framework - java based e-commerce applications\n",
      " earned the credential oracle atg web commerce suite 10 implementation developer certified\n",
      "implementation specialist and is recognized by oracle university as a certified specialist\n",
      " currently working as a senior developer in professional access software development pvt. ltd.\n",
      " have worked in technology excellence group's retail multi-channel practice as a developer in tata\n",
      "consultancy services, chennai\n",
      " gained expertise in atg framework, java/j2ee and restful webservices.\n",
      "\n",
      "                                                  --------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.7324 - val_acc: 0.8426\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0297 - acc: 0.9895 - val_loss: 1.0198 - val_acc: 0.8347\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0298 - acc: 0.9885 - val_loss: 1.2313 - val_acc: 0.8167\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0285 - acc: 0.9920 - val_loss: 0.9279 - val_acc: 0.8207\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0271 - acc: 0.9910 - val_loss: 0.9621 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0295 - acc: 0.9925 - val_loss: 0.6974 - val_acc: 0.8048\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0277 - acc: 0.9890 - val_loss: 0.6671 - val_acc: 0.8167\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0287 - acc: 0.9890 - val_loss: 0.8861 - val_acc: 0.7988\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 51s 25ms/step - loss: 0.0294 - acc: 0.9910 - val_loss: 1.1717 - val_acc: 0.8247\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 47s 24ms/step - loss: 0.0267 - acc: 0.9905 - val_loss: 1.5298 - val_acc: 0.8088\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0307 - acc: 0.9885 - val_loss: 0.9233 - val_acc: 0.7908\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0253 - acc: 0.9915 - val_loss: 1.0621 - val_acc: 0.7669\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0307 - acc: 0.9885 - val_loss: 0.9078 - val_acc: 0.8327\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 47s 24ms/step - loss: 0.0246 - acc: 0.9915 - val_loss: 0.6652 - val_acc: 0.8247\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 50s 25ms/step - loss: 0.0256 - acc: 0.9925 - val_loss: 1.4360 - val_acc: 0.8287\n",
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 45s 22ms/step - loss: 0.0314 - acc: 0.9885 - val_loss: 1.1304 - val_acc: 0.8108\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0280 - acc: 0.9920 - val_loss: 0.9148 - val_acc: 0.8386\n",
      "Epoch 18/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0249 - acc: 0.9920 - val_loss: 1.0967 - val_acc: 0.8247\n",
      "Epoch 19/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0241 - acc: 0.9915 - val_loss: 1.3266 - val_acc: 0.8267\n",
      "Epoch 20/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0264 - acc: 0.9920 - val_loss: 1.3139 - val_acc: 0.8307\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "applications. presently working as a senior development manager with oracle india pvt\n",
      "ltd., noida. a self motivated seasoned problem-solver, coder and a manager who gives\n",
      "technical direction to the team with proven success in building and integrating stellar\n",
      "development teams and delivering innovative enterprise software solutions. articulates a\n",
      "vision to drive the business and the product teams to realize the opportunities.\n",
      "expertise in high and low level designing, coding (ui and backend), product vision, code\n",
      "reviews, debugging, handling critical customer issues, managing quality on time deliveries,\n",
      "across geography team management, problem solving, interviewing, employee retention,\n",
      "working in a startup like environment.\n",
      "objective\n",
      "being a part of a team/organization that believes in customer/market centric delivery with\n",
      "quality, has cordial and converging work atmosphere giving a chance to learn new things\n",
      "every day that would help me boost my professional career and technical expertise and\n",
      "shape me as a better leader, a better engineer and also a better human being\n",
      "educational qualification\n",
      "qualification institute marks year\n",
      "b.e. in computer science\n",
      "punjab engineering college,\n",
      "chandigarh\n",
      "73.8%\n",
      "2004\n",
      "class 12th (c.b.s.e) d.a.v. college, chandigarh 83.2% 2000\n",
      "class 10th (i.c.s.e) st. edward’s school, shimla 93.2% 1998\n",
      "employment history\n",
      "company period designation work area/responsibilities\n",
      "oracle india private\n",
      "limited, noida\n",
      "may-2008 to present senior software\n",
      "development\n",
      "manager\n",
      "design, coding, managing\n",
      "distributed teams, agile, scrum,\n",
      "code reviews, hiring, customer\n",
      "issues, managing multiple\n",
      "products’ development and\n",
      "releases, high availability, load\n",
      "balancing, web services, rest\n",
      "apis, scripting, ui\n",
      "development,\n",
      "public/private/hybrid cloud\n",
      "mailto:avaidya3008@gmail.com\n",
      "adobe systems,\n",
      "noida\n",
      "microsoft word - anil_prabhu_resume.rtf\n",
      "address: #109/19/2 ‘hira sadan’,\n",
      "7th cross lower palace orchards,\n",
      "bangalore -560003.\n",
      "email:anilprabhu1988@gmail.com\n",
      "mobile: +91-9886594775\n",
      "anil prabhu\n",
      "\n",
      "---OUTPUT-----\n",
      "applications. presently working as a senior development manager with oracle india pvt\n",
      "ltd., noida. a self motivated seasoned problem-solver, coder and a manager who gives\n",
      "technical direction to the team with proven success in building and integrating stellar\n",
      "development teams and delivering innovative enterprise software solutions. articulates a\n",
      "vision to drive the business and the product teams to realize the opportunities.\n",
      "expertise in high and low level designing, coding (ui and backend), product vision, code\n",
      "reviews, debugging, handling critical customer issues, managing quality on time deliveries,\n",
      "across geography team management, problem solving, interviewing, employee retention,\n",
      "working in a startup like environment.\n",
      "objective\n",
      "being a part of a team/organization that believes in customer/market centric delivery with\n",
      "quality, has cordial and converging work atmosphere giving a chance to learn new things\n",
      "every day that would help me boost my professional career and technical expertise and\n",
      "shape me as a better leader, a better engineer and also a better human being\n",
      "\n",
      "                                                  --------------------------------------------------\n",
      "Iteration: 7\n",
      "Train on 2008 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0305 - acc: 0.9900 - val_loss: 1.1217 - val_acc: 0.8108\n",
      "Epoch 2/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0338 - acc: 0.9895 - val_loss: 0.9931 - val_acc: 0.8267\n",
      "Epoch 3/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0226 - acc: 0.9895 - val_loss: 1.1249 - val_acc: 0.8367\n",
      "Epoch 4/20\n",
      "2008/2008 [==============================] - 45s 22ms/step - loss: 0.0234 - acc: 0.9905 - val_loss: 1.2435 - val_acc: 0.8187\n",
      "Epoch 5/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0278 - acc: 0.9890 - val_loss: 0.9596 - val_acc: 0.8227\n",
      "Epoch 6/20\n",
      "2008/2008 [==============================] - 45s 23ms/step - loss: 0.0294 - acc: 0.9905 - val_loss: 0.9903 - val_acc: 0.8127\n",
      "Epoch 7/20\n",
      "2008/2008 [==============================] - 49s 24ms/step - loss: 0.0212 - acc: 0.9915 - val_loss: 1.1441 - val_acc: 0.8008\n",
      "Epoch 8/20\n",
      "2008/2008 [==============================] - 54s 27ms/step - loss: 0.0246 - acc: 0.9925 - val_loss: 1.0075 - val_acc: 0.8127\n",
      "Epoch 9/20\n",
      "2008/2008 [==============================] - 53s 27ms/step - loss: 0.0254 - acc: 0.9885 - val_loss: 1.1321 - val_acc: 0.8167\n",
      "Epoch 10/20\n",
      "2008/2008 [==============================] - 51s 25ms/step - loss: 0.0217 - acc: 0.9920 - val_loss: 1.3395 - val_acc: 0.8127\n",
      "Epoch 11/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0264 - acc: 0.9930 - val_loss: 1.0599 - val_acc: 0.8227\n",
      "Epoch 12/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0244 - acc: 0.9925 - val_loss: 1.1747 - val_acc: 0.8167\n",
      "Epoch 13/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0230 - acc: 0.9905 - val_loss: 1.1194 - val_acc: 0.8048\n",
      "Epoch 14/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0219 - acc: 0.9900 - val_loss: 1.5622 - val_acc: 0.8088\n",
      "Epoch 15/20\n",
      "2008/2008 [==============================] - 46s 23ms/step - loss: 0.0214 - acc: 0.9920 - val_loss: 1.7705 - val_acc: 0.8028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2008/2008 [==============================] - 47s 23ms/step - loss: 0.0261 - acc: 0.9910 - val_loss: 1.1058 - val_acc: 0.8207\n",
      "Epoch 17/20\n",
      "2008/2008 [==============================] - 48s 24ms/step - loss: 0.0207 - acc: 0.9920 - val_loss: 1.2589 - val_acc: 0.8227\n",
      "Epoch 18/20\n",
      "1024/2008 [==============>...............] - ETA: 20s - loss: 0.0152 - acc: 0.9961"
     ]
    }
   ],
   "source": [
    "\n",
    "iteration=0\n",
    "\"\"\"\n",
    "# load weights\n",
    "print('loading the weights')\n",
    "model=load_model('resume_level.h5')\n",
    "\n",
    "# estimate accuracy on whole dataset using loaded weights\n",
    "scores = model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data,verbose=0)\n",
    "print(\"%s: %.2f%%\\n\\n\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"Testing Samples\\n\"+\"-\"*50)\n",
    "for i in range(1):\n",
    "    index=np.random.randint(len(input_resumes))\n",
    "    encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "    output_sequence=decode_sequence(encoded_input_sequence)\n",
    "    print(\"-\"*50)\n",
    "    print(input_resumes[index])\n",
    "    print(\" \"*50)\n",
    "    print(\"*\"*50+\"\\nOUTPUT\"+\" \"*50)\n",
    "    print(output_sequence)\n",
    "    print(\"-\"*50+\"\\n\"+\" \"*50)\n",
    "\"\"\"\n",
    "iteration_file=\"/home/santhosh/resumes_folder/keras/extract_summary_and_objective/iteration_resume_line_classification.txt\"\n",
    "try:\n",
    "    file=open(iteration_file,'r')\n",
    "    last_line=file.read().split('\\n')[-2]\n",
    "    print('file_data,',last_line)\n",
    "    iteration=int(last_line.split(':')[1])\n",
    "    #print(iteration)\n",
    "    file.close()\n",
    "    \n",
    "except:\n",
    "    print('no file exist')\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"resume_line_classification_checkpoints.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "while True:\n",
    "    print('Iteration:',iteration+1)\n",
    "    #training\n",
    "    model.fit(encoder_input_data,decoder_target_data ,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,callbacks=callbacks_list)\n",
    "    \n",
    "    #prepare sample_data to test 5 samples:\n",
    "    print(\"-\"*50)\n",
    "    index=int(np.random.randint(len(input_resumes)/40*0.8)*40)\n",
    "    test_input=\"\"\n",
    "    test_output=\"\"\n",
    "    for i in range(50):\n",
    "        \n",
    "        encoded_input_sequence=encoder_input_data[index: index + 1]\n",
    "        output_sequence=model.predict(encoded_input_sequence, verbose=0)[0]\n",
    "        output_sequence = output_index2token[np.argmax(output_sequence)]\n",
    "        test_input+=input_resumes[index]+'\\n'\n",
    "        if output_sequence==\"1\":\n",
    "            output_sequence=input_resumes[index]+'\\n'\n",
    "        else:\n",
    "            output_sequence=''\n",
    "        test_output+=output_sequence\n",
    "        index+=1\n",
    "    print(\"-\"*50)\n",
    "    print(test_input)\n",
    "    print(\"---OUTPUT-----\")\n",
    "    print(test_output)\n",
    "    print(\" \"*50+\"-\"*50)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Save model\n",
    "    file=open(iteration_file,'a')\n",
    "    file.write('iteration:'+str(iteration+1)+'\\n')\n",
    "    file.close()\n",
    "    iteration+=1\n",
    "    model.save('resume_line_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
